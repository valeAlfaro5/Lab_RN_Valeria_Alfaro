{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa11ba5c-c01c-43d3-86e8-19a7b7400afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import DnnLib\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02a3552-4536-4d93-9a79-98c64ca89055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de datos\n",
    "with open(\"mnist_mlp_pretty.json\", \"r\") as f:\n",
    "    datos = json.load(f)\n",
    "\n",
    "#carga imagenes y labels\n",
    "data = np.load(\"mnist_test.npz\")\n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "pruebas = np.load(\"mnist_train.npz\")\n",
    "image = pruebas[\"images\"]\n",
    "label = pruebas[\"labels\"]\n",
    "\n",
    "#capa1\n",
    "w1 = np.array(datos[\"layers\"][0][\"W\"])\n",
    "b1 = np.array(datos[\"layers\"][0][\"b\"])\n",
    "\n",
    "#capa2\n",
    "w2 = np.array(datos[\"layers\"][1][\"W\"])\n",
    "b2 = np.array(datos[\"layers\"][1][\"b\"])\n",
    "\n",
    "#activación por capa\n",
    "activate1 = datos[\"layers\"][0][\"activation\"]\n",
    "activate2 = datos[\"layers\"][1][\"activation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d02c5d4-95ac-4118-bb77-0e8c5ab0b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 128) (128,) (128, 10) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(w1.shape, b1.shape, w2.shape, b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b23274-7c71-418c-b5d3-d73db638e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir capas densas (ambas son densas segun el json) - parte 3\n",
    "#primera capa tiene 784 entradas y 128 salidas, activacion relu\n",
    "layer1 = DnnLib.DenseLayer(784, 128, DnnLib.ActivationType.RELU)\n",
    "#segunda capa tiene 128 entradas(de capa 1) y 10 de salida, activacion softmax\n",
    "layer2 = DnnLib.DenseLayer(128, 10, DnnLib.ActivationType.SOFTMAX)\n",
    "\n",
    "#definir pesos y biases tomados del archivo\n",
    "#transponer para evitar errores\n",
    "layer1.weights = w1.T\n",
    "layer1.bias = b1.T\n",
    "layer2.weights = w2.T\n",
    "layer2.bias = b2.T\n",
    "\n",
    "x = np.random.rand(1, 784)\n",
    "\n",
    "output = layer1.forward(x)\n",
    "salida = layer2.forward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc25efe-5742-44d2-a4da-2f883223dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida capa 1: (1, 128)\n",
      "Salida capa 2: (1, 10)\n",
      "Predicción: 0.0\n"
     ]
    }
   ],
   "source": [
    "#predicciones de prueba\n",
    "predict = np.argmax(salida, axis =1)\n",
    "#acurracy\n",
    "acurracy = np.mean(predict == x)\n",
    "\n",
    "#verificar que funcione la salidas de cada una con su predicción\n",
    "print(\"Salida capa 1:\", output.shape)\n",
    "print(\"Salida capa 2:\", salida.shape)\n",
    "print(\"Predicción:\", acurracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73df5400-40c0-4321-becd-afed43efcf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probar con el mnist train\n",
    "#asegurar que tengan 784 entradas\n",
    "c = images.reshape(-1, 784)\n",
    "#normalizar\n",
    "c = c/255\n",
    "\n",
    "#asegurar que tengan 784 entradas\n",
    "f = image.reshape(-1, 784) / 255\n",
    "\n",
    "#forward de ambas capas con las imagenes\n",
    "out = layer1.forward(c)\n",
    "sal = layer2.forward(out)\n",
    "\n",
    "#forward con entrenamiento\n",
    "salidas = layer1.forward(f)\n",
    "outs = layer2.forward(salidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2d9b94-9ac4-4a06-abc3-158d3f3571ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción test: 96.66\n",
      "Predicción entrenamiento: 97.10666666666667\n"
     ]
    }
   ],
   "source": [
    "# Para test\n",
    "predicts = np.argmax(sal, axis=1)\n",
    "acurr = np.mean(predicts == labels)   # (test)\n",
    "print(\"Predicción test:\", acurr * 100)\n",
    "\n",
    "# Para entrenamiento\n",
    "predicts = np.argmax(outs, axis=1)\n",
    "acurr = np.mean(predicts == label)    #   (train)\n",
    "print(\"Predicción entrenamiento:\", acurr * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9baee6-e45a-4411-8a9e-4de782b3e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arreglo de layers ya definidio, arreglo de todos los optimizadores, f son las entradas del mnist-train, y es el one hot, label a lo que estoy comparando y epochs epocas predefinidas, batch sizes para que pueda correr sin tronar \n",
    "def entrenamiento1(capas, optimizer, f, y_onehot, label, epochs=50, batch_size=128):\n",
    "    n = f.shape[0]\n",
    "    for e in range(epochs):\n",
    "        # barajar los datos\n",
    "        indices = np.random.permutation(n)\n",
    "        f, y_onehot, label = f[indices], y_onehot[indices], label[indices]\n",
    "\n",
    "        # mini-batches\n",
    "        for i in range(0, n, batch_size):\n",
    "            X_batch = f[i:i+batch_size]\n",
    "            y_batch = y_onehot[i:i+batch_size]\n",
    "            label_batch = label[i:i+batch_size]\n",
    "\n",
    "            # forward\n",
    "            out1 = capas[0].forward(X_batch)\n",
    "            out2 = capas[1].forward(out1)\n",
    "\n",
    "            # backward y update\n",
    "            grad = DnnLib.cross_entropy_gradient(out2, y_batch)\n",
    "            grad = capas[1].backward(grad)\n",
    "            grad = capas[0].backward(grad)\n",
    "\n",
    "            optimizer.update(capas[1])\n",
    "            optimizer.update(capas[0])\n",
    "\n",
    "        # imprimir cada 10 épocas\n",
    "        if e % 10 == 0:\n",
    "            preds = np.argmax(out2, axis=1)\n",
    "            acc = np.mean(preds == label_batch)\n",
    "            print(f\"Epoch {e}, Loss: {DnnLib.cross_entropy(out2, y_batch):.4f}, Acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa0d9ca-57b7-4064-ba82-2363345f0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamiento de red neuronal - parte 4\n",
    "#creando arreglos & variables necesarias\n",
    "\n",
    "capa1 = DnnLib.DenseLayer(784, 128, DnnLib.ActivationType.RELU)\n",
    "#segunda capa tiene 128 entradas(de capa 1) y 10 de salida, activacion softmax\n",
    "capa2 = DnnLib.DenseLayer(128, 10, DnnLib.ActivationType.SOFTMAX)\n",
    "\n",
    "capa1.weights = np.random.randn(128,784)*0.01\n",
    "capa1.bias = np.zeros(128,)\n",
    "capa2.weights = np.random.randn(10, 128)*0.01\n",
    "capa2.bias = np.zeros(10,)\n",
    "\n",
    "capa = [capa1, capa2]\n",
    "\n",
    "#arreglo de optimizadores\n",
    "optimizers = [\n",
    "    (\"Adam\", DnnLib.Adam(0.001))\n",
    "]\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "#creación de one hot\n",
    "n = label.shape[0]  \n",
    "y = np.zeros((n, 10), dtype=np.float64)\n",
    "y[np.arange(n), label] = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a1db4-b92a-4361-b09d-998bf6a1250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5311, Acc: 0.8854\n"
     ]
    }
   ],
   "source": [
    "#llamada de función de entrenamiento\n",
    "per = []\n",
    "per = entrenamiento1(capa, optimizers[0][1], f, y, label, epochs)\n",
    "print(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a57090-7e7f-4c1d-a733-c717677419d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
