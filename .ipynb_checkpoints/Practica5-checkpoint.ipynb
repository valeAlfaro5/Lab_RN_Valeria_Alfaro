{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cc0f36a-efa5-470e-b83f-144038391699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE Train shape: (60000, 784) Test shape: (10000, 784)\n",
      "LABEL Train shape: (60000, 784) Test shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import DnnLib\n",
    "import json\n",
    "\n",
    "# carga datos de npz para labels e imagenes\n",
    "prueba = np.load(\"fashion_mnist_train.npz\")\n",
    "test = np.load(\"fashion_mnist_test.npz\")\n",
    "\n",
    "#separar en labels e imagenes\n",
    "imagenes = prueba[\"images\"]\n",
    "labelE = prueba[\"labels\"]\n",
    "\n",
    "imagens = test[\"images\"]\n",
    "labelP = test[\"labels\"]\n",
    "\n",
    "print(\"IMAGE Train shape:\", imagenE.shape, \"Test shape:\", imagenP.shape)\n",
    "print(\"LABEL Train shape:\", imagenE.shape, \"Test shape:\", imagenP.shape)\n",
    "\n",
    "# funcion de one hot\n",
    "def to_one_hot(labels, num_classes=10):\n",
    "    h = np.zeros((labels.shape[0], num_classes), dtype=np.float32)\n",
    "    h[np.arange(labels.shape[0]), labels] = 1\n",
    "    return h\n",
    "\n",
    "#one hot para cada labels\n",
    "yE = to_one_hot(labelE)\n",
    "yP = to_one_hot(labelP)\n",
    "\n",
    "# cargar json\n",
    "def load_datos():\n",
    "    with open(\"mnist_entrenado.json\", \"r\") as f:\n",
    "        datos = json.load(f)\n",
    "\n",
    "    # Capa 1 y regularizador\n",
    "    layer1 = DnnLib.DenseLayer(784, 128, DnnLib.ActivationType.RELU)\n",
    "    layer1.set_regularizer(DnnLib.RegularizerType.L2, 0.001)\n",
    "\n",
    "    # Dropout\n",
    "    dropout1 = DnnLib.Dropout(dropout_rate=0.5)\n",
    "\n",
    "    # Capa 2 y regularizador\n",
    "    layer2 = DnnLib.DenseLayer(128, 10, DnnLib.ActivationType.SOFTMAX)\n",
    "    layer2.set_regularizer(DnnLib.RegularizerType.L2, 0.001)\n",
    "\n",
    "    # layer1.weights = np.array(datos[\"layers\"][0][\"W\"], dtype=np.float32) # (128,784)\n",
    "    # layer1.bias = np.array(datos[\"layers\"][0][\"b\"], dtype=np.float32)  # (128,)\n",
    "\n",
    "    # layer2.weights = np.array(datos[\"layers\"][1][\"W\"], dtype=np.float32)  # (10,128)\n",
    "    # layer2.bias = np.array(datos[\"layers\"][1][\"b\"], dtype=np.float32)  # (10,)\n",
    "\n",
    "    return [layer1, dropout1, layer2]\n",
    "\n",
    "#funciones de forward y backward para droupout\n",
    "def forward_pass_with_dropout(layers, x, training=True):\n",
    "    activation = x\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, DnnLib.Dropout):\n",
    "            layer.training = training\n",
    "        activation = layer.forward(activation)\n",
    "    return activation\n",
    "\n",
    "def backward_pass_with_dropout(layers, grad_output):\n",
    "    grad = grad_output\n",
    "    for layer in reversed(layers):\n",
    "        grad = layer.backward(grad)\n",
    "    return grad\n",
    "\n",
    "def entrenamiento(capas, optimizers, x, y, label, epochs=50, batches=128):\n",
    "    n = x.shape[0]\n",
    "    for e in range(epochs):\n",
    "        r = np.random.permutation(n)\n",
    "        # print(\"Bajado correcto 1\")\n",
    "        x_shuffled = x[r]\n",
    "        y_shuffled = y[r]\n",
    "        labels = label[r]\n",
    "        # print(\"Bajado correcto 2\")\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        n_batches, correct, total = 0, 0, 0\n",
    "\n",
    "        for i in range(0, n, batches):\n",
    "            x_batch = x_shuffled[i:i+batches]\n",
    "            y_batch = y_shuffled[i:i+batches]\n",
    "            label_batch = labels[i:i+batches]\n",
    "            # print(\"Bajado correcto 3\")\n",
    "\n",
    "            # forward y dropout \n",
    "            output = forward_pass_with_dropout(capas, x_batch, training=True)\n",
    "\n",
    "            # perdida\n",
    "            perdida = DnnLib.cross_entropy(output, y_batch)\n",
    "\n",
    "            # regularizar\n",
    "            # total_reg_loss = capas[0].compute_regularization_loss() + capas[2].compute_regularization_loss()\n",
    "            # data_loss = perdida + total_reg_loss\n",
    "\n",
    "            # backward con dropout\n",
    "            gradiente = DnnLib.softmax_crossentropy_gradient(output, y_batch)\n",
    "            gradiente = backward_pass_with_dropout(capas, gradiente)\n",
    "\n",
    "            # Actualizar capas (no dropout)\n",
    "            optimizers.update(capas[2])\n",
    "            optimizers.update(capas[0])\n",
    "\n",
    "            epoch_loss += perdida\n",
    "            n_batches += 1\n",
    "            preds = np.argmax(output, axis=1)\n",
    "            correct += np.sum(preds == label_batch)\n",
    "            total += len(label_batch)\n",
    "\n",
    "            # if e % 2 == 0:\n",
    "                # val_output = forward_pass_with_dropout(capas, imt, training=False)\n",
    "                # val_loss = DnnLib.cross_entropy(val_output, labelt)\n",
    "                # print(f\"Epoch {e}, Train Loss: {perdida:.4f}\")\n",
    "            #     print(f\"Reg Loss: {total_reg_loss:.4f}, Total: {data_loss:.4f}\")\n",
    "\n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {e}, Avg Loss: {avg_loss:.4f}, Acc: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9618a419-0439-41c7-8ab4-bebcb3ab4693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 2.3027\n",
      "Epoch 0, Train Loss: 2.3021\n",
      "Epoch 0, Train Loss: 2.3005\n",
      "Epoch 0, Train Loss: 2.3007\n",
      "Epoch 0, Train Loss: 2.2996\n",
      "Epoch 0, Train Loss: 2.2990\n",
      "Epoch 0, Train Loss: 2.2989\n",
      "Epoch 0, Train Loss: 2.2971\n",
      "Epoch 0, Train Loss: 2.2987\n",
      "Epoch 0, Train Loss: 2.2940\n",
      "Epoch 0, Train Loss: 2.2933\n",
      "Epoch 0, Train Loss: 2.2940\n",
      "Epoch 0, Train Loss: 2.2961\n",
      "Epoch 0, Train Loss: 2.2912\n",
      "Epoch 0, Train Loss: 2.2921\n",
      "Epoch 0, Train Loss: 2.2906\n",
      "Epoch 0, Train Loss: 2.2898\n",
      "Epoch 0, Train Loss: 2.2906\n",
      "Epoch 0, Train Loss: 2.2867\n",
      "Epoch 0, Train Loss: 2.2865\n",
      "Epoch 0, Train Loss: 2.2861\n",
      "Epoch 0, Train Loss: 2.2844\n",
      "Epoch 0, Train Loss: 2.2848\n",
      "Epoch 0, Train Loss: 2.2771\n",
      "Epoch 0, Train Loss: 2.2831\n",
      "Epoch 0, Train Loss: 2.2823\n",
      "Epoch 0, Train Loss: 2.2786\n",
      "Epoch 0, Train Loss: 2.2818\n",
      "Epoch 0, Train Loss: 2.2775\n",
      "Epoch 0, Train Loss: 2.2761\n",
      "Epoch 0, Train Loss: 2.2751\n",
      "Epoch 0, Train Loss: 2.2798\n",
      "Epoch 0, Train Loss: 2.2742\n",
      "Epoch 0, Train Loss: 2.2695\n",
      "Epoch 0, Train Loss: 2.2685\n",
      "Epoch 0, Train Loss: 2.2683\n",
      "Epoch 0, Train Loss: 2.2688\n",
      "Epoch 0, Train Loss: 2.2605\n",
      "Epoch 0, Train Loss: 2.2609\n",
      "Epoch 0, Train Loss: 2.2640\n",
      "Epoch 0, Train Loss: 2.2636\n",
      "Epoch 0, Train Loss: 2.2665\n",
      "Epoch 0, Train Loss: 2.2578\n",
      "Epoch 0, Train Loss: 2.2547\n",
      "Epoch 0, Train Loss: 2.2546\n",
      "Epoch 0, Train Loss: 2.2511\n",
      "Epoch 0, Train Loss: 2.2534\n",
      "Epoch 0, Train Loss: 2.2481\n",
      "Epoch 0, Train Loss: 2.2460\n",
      "Epoch 0, Train Loss: 2.2413\n",
      "Epoch 0, Train Loss: 2.2476\n",
      "Epoch 0, Train Loss: 2.2391\n",
      "Epoch 0, Train Loss: 2.2404\n",
      "Epoch 0, Train Loss: 2.2396\n",
      "Epoch 0, Train Loss: 2.2387\n",
      "Epoch 0, Train Loss: 2.2394\n",
      "Epoch 0, Train Loss: 2.2250\n",
      "Epoch 0, Train Loss: 2.2260\n",
      "Epoch 0, Train Loss: 2.2250\n",
      "Epoch 0, Train Loss: 2.2168\n",
      "Epoch 0, Train Loss: 2.2184\n",
      "Epoch 0, Train Loss: 2.2252\n",
      "Epoch 0, Train Loss: 2.2260\n",
      "Epoch 0, Train Loss: 2.2111\n",
      "Epoch 0, Train Loss: 2.2051\n",
      "Epoch 0, Train Loss: 2.2102\n",
      "Epoch 0, Train Loss: 2.2063\n",
      "Epoch 0, Train Loss: 2.2085\n",
      "Epoch 0, Train Loss: 2.2048\n",
      "Epoch 0, Train Loss: 2.1925\n",
      "Epoch 0, Train Loss: 2.1926\n",
      "Epoch 0, Train Loss: 2.1934\n",
      "Epoch 0, Train Loss: 2.1883\n",
      "Epoch 0, Train Loss: 2.1752\n",
      "Epoch 0, Train Loss: 2.1709\n",
      "Epoch 0, Train Loss: 2.1726\n",
      "Epoch 0, Train Loss: 2.1812\n",
      "Epoch 0, Train Loss: 2.1717\n",
      "Epoch 0, Train Loss: 2.1727\n",
      "Epoch 0, Train Loss: 2.1627\n",
      "Epoch 0, Train Loss: 2.1614\n",
      "Epoch 0, Train Loss: 2.1576\n",
      "Epoch 0, Train Loss: 2.1499\n",
      "Epoch 0, Train Loss: 2.1495\n",
      "Epoch 0, Train Loss: 2.1605\n",
      "Epoch 0, Train Loss: 2.1500\n",
      "Epoch 0, Train Loss: 2.1313\n",
      "Epoch 0, Train Loss: 2.1458\n",
      "Epoch 0, Train Loss: 2.1399\n",
      "Epoch 0, Train Loss: 2.1264\n",
      "Epoch 0, Train Loss: 2.1411\n",
      "Epoch 0, Train Loss: 2.1141\n",
      "Epoch 0, Train Loss: 2.1179\n",
      "Epoch 0, Train Loss: 2.1291\n",
      "Epoch 0, Train Loss: 2.1140\n",
      "Epoch 0, Train Loss: 2.0969\n",
      "Epoch 0, Train Loss: 2.1141\n",
      "Epoch 0, Train Loss: 2.0958\n",
      "Epoch 0, Train Loss: 2.1009\n",
      "Epoch 0, Train Loss: 2.0940\n",
      "Epoch 0, Train Loss: 2.0956\n",
      "Epoch 0, Train Loss: 2.0783\n",
      "Epoch 0, Train Loss: 2.0852\n",
      "Epoch 0, Train Loss: 2.0643\n",
      "Epoch 0, Train Loss: 2.0665\n",
      "Epoch 0, Train Loss: 2.0821\n",
      "Epoch 0, Train Loss: 2.0587\n",
      "Epoch 0, Train Loss: 2.0485\n",
      "Epoch 0, Train Loss: 2.0426\n",
      "Epoch 0, Train Loss: 2.0505\n",
      "Epoch 0, Train Loss: 2.0357\n",
      "Epoch 0, Train Loss: 2.0383\n",
      "Epoch 0, Train Loss: 2.0276\n",
      "Epoch 0, Train Loss: 2.0450\n",
      "Epoch 0, Train Loss: 2.0311\n",
      "Epoch 0, Train Loss: 2.0146\n",
      "Epoch 0, Train Loss: 1.9954\n",
      "Epoch 0, Train Loss: 2.0173\n",
      "Epoch 0, Train Loss: 1.9783\n",
      "Epoch 0, Train Loss: 2.0142\n",
      "Epoch 0, Train Loss: 2.0008\n",
      "Epoch 0, Train Loss: 1.9962\n",
      "Epoch 0, Train Loss: 2.0057\n",
      "Epoch 0, Train Loss: 1.9777\n",
      "Epoch 0, Train Loss: 1.9919\n",
      "Epoch 0, Train Loss: 1.9721\n",
      "Epoch 0, Train Loss: 1.9869\n",
      "Epoch 0, Train Loss: 1.9636\n",
      "Epoch 0, Train Loss: 1.9575\n",
      "Epoch 0, Train Loss: 1.9496\n",
      "Epoch 0, Train Loss: 1.9638\n",
      "Epoch 0, Train Loss: 1.9239\n",
      "Epoch 0, Train Loss: 1.9232\n",
      "Epoch 0, Train Loss: 1.9519\n",
      "Epoch 0, Train Loss: 1.9732\n",
      "Epoch 0, Train Loss: 1.9275\n",
      "Epoch 0, Train Loss: 1.9220\n",
      "Epoch 0, Train Loss: 1.9155\n",
      "Epoch 0, Train Loss: 1.9165\n",
      "Epoch 0, Train Loss: 1.9277\n",
      "Epoch 0, Train Loss: 1.9143\n",
      "Epoch 0, Train Loss: 1.8695\n",
      "Epoch 0, Train Loss: 1.9141\n",
      "Epoch 0, Train Loss: 1.9105\n",
      "Epoch 0, Train Loss: 1.8712\n",
      "Epoch 0, Train Loss: 1.8741\n",
      "Epoch 0, Train Loss: 1.8843\n",
      "Epoch 0, Train Loss: 1.8615\n",
      "Epoch 0, Train Loss: 1.8933\n",
      "Epoch 0, Train Loss: 1.8336\n",
      "Epoch 0, Train Loss: 1.8670\n",
      "Epoch 0, Train Loss: 1.8459\n",
      "Epoch 0, Train Loss: 1.8533\n",
      "Epoch 0, Train Loss: 1.8478\n",
      "Epoch 0, Train Loss: 1.8470\n",
      "Epoch 0, Train Loss: 1.8639\n",
      "Epoch 0, Train Loss: 1.8029\n",
      "Epoch 0, Train Loss: 1.8325\n",
      "Epoch 0, Train Loss: 1.7910\n",
      "Epoch 0, Train Loss: 1.7995\n",
      "Epoch 0, Train Loss: 1.8399\n",
      "Epoch 0, Train Loss: 1.8184\n",
      "Epoch 0, Train Loss: 1.7849\n",
      "Epoch 0, Train Loss: 1.7710\n",
      "Epoch 0, Train Loss: 1.8057\n",
      "Epoch 0, Train Loss: 1.8157\n",
      "Epoch 0, Train Loss: 1.8099\n",
      "Epoch 0, Train Loss: 1.8101\n",
      "Epoch 0, Train Loss: 1.7542\n",
      "Epoch 0, Train Loss: 1.7575\n",
      "Epoch 0, Train Loss: 1.7435\n",
      "Epoch 0, Train Loss: 1.7649\n",
      "Epoch 0, Train Loss: 1.7596\n",
      "Epoch 0, Train Loss: 1.7857\n",
      "Epoch 0, Train Loss: 1.7323\n",
      "Epoch 0, Train Loss: 1.7475\n",
      "Epoch 0, Train Loss: 1.7567\n",
      "Epoch 0, Train Loss: 1.7462\n",
      "Epoch 0, Train Loss: 1.7020\n",
      "Epoch 0, Train Loss: 1.7395\n",
      "Epoch 0, Train Loss: 1.7488\n",
      "Epoch 0, Train Loss: 1.7077\n",
      "Epoch 0, Train Loss: 1.7254\n",
      "Epoch 0, Train Loss: 1.6955\n",
      "Epoch 0, Train Loss: 1.6923\n",
      "Epoch 0, Train Loss: 1.7056\n",
      "Epoch 0, Train Loss: 1.7136\n",
      "Epoch 0, Train Loss: 1.7189\n",
      "Epoch 0, Train Loss: 1.6986\n",
      "Epoch 0, Train Loss: 1.6823\n",
      "Epoch 0, Train Loss: 1.6301\n",
      "Epoch 0, Train Loss: 1.6629\n",
      "Epoch 0, Train Loss: 1.6794\n",
      "Epoch 0, Train Loss: 1.6619\n",
      "Epoch 0, Train Loss: 1.6598\n",
      "Epoch 0, Train Loss: 1.6680\n",
      "Epoch 0, Train Loss: 1.7083\n",
      "Epoch 0, Train Loss: 1.6466\n",
      "Epoch 0, Train Loss: 1.6646\n",
      "Epoch 0, Train Loss: 1.6615\n",
      "Epoch 0, Train Loss: 1.6581\n",
      "Epoch 0, Train Loss: 1.6173\n",
      "Epoch 0, Train Loss: 1.6284\n",
      "Epoch 0, Train Loss: 1.6142\n",
      "Epoch 0, Train Loss: 1.6281\n",
      "Epoch 0, Train Loss: 1.5807\n",
      "Epoch 0, Train Loss: 1.6734\n",
      "Epoch 0, Train Loss: 1.6247\n",
      "Epoch 0, Train Loss: 1.6947\n",
      "Epoch 0, Train Loss: 1.6661\n",
      "Epoch 0, Train Loss: 1.6404\n",
      "Epoch 0, Train Loss: 1.5949\n",
      "Epoch 0, Train Loss: 1.6233\n",
      "Epoch 0, Train Loss: 1.6417\n",
      "Epoch 0, Train Loss: 1.6702\n",
      "Epoch 0, Train Loss: 1.6199\n",
      "Epoch 0, Train Loss: 1.5800\n",
      "Epoch 0, Train Loss: 1.6863\n",
      "Epoch 0, Train Loss: 1.5901\n",
      "Epoch 0, Train Loss: 1.5762\n",
      "Epoch 0, Train Loss: 1.5764\n",
      "Epoch 0, Train Loss: 1.5950\n",
      "Epoch 0, Train Loss: 1.5750\n",
      "Epoch 0, Train Loss: 1.5301\n",
      "Epoch 0, Train Loss: 1.5272\n",
      "Epoch 0, Train Loss: 1.5878\n",
      "Epoch 0, Train Loss: 1.5907\n",
      "Epoch 0, Train Loss: 1.5591\n",
      "Epoch 0, Train Loss: 1.6417\n",
      "Epoch 0, Train Loss: 1.5785\n",
      "Epoch 0, Train Loss: 1.6351\n",
      "Epoch 0, Train Loss: 1.5466\n",
      "Epoch 0, Train Loss: 1.6046\n",
      "Epoch 0, Train Loss: 1.5001\n",
      "Epoch 0, Train Loss: 1.5049\n",
      "Epoch 0, Train Loss: 1.6419\n",
      "Epoch 0, Train Loss: 1.5543\n",
      "Epoch 0, Train Loss: 1.5430\n",
      "Epoch 0, Train Loss: 1.5566\n",
      "Epoch 0, Train Loss: 1.4753\n",
      "Epoch 0, Train Loss: 1.5577\n",
      "Epoch 0, Train Loss: 1.5719\n",
      "Epoch 0, Train Loss: 1.5519\n",
      "Epoch 0, Train Loss: 1.5222\n",
      "Epoch 0, Train Loss: 1.5397\n",
      "Epoch 0, Train Loss: 1.5187\n",
      "Epoch 0, Train Loss: 1.4955\n",
      "Epoch 0, Train Loss: 1.5145\n",
      "Epoch 0, Train Loss: 1.4909\n",
      "Epoch 0, Train Loss: 1.4869\n",
      "Epoch 0, Train Loss: 1.5020\n",
      "Epoch 0, Train Loss: 1.5219\n",
      "Epoch 0, Train Loss: 1.5488\n",
      "Epoch 0, Train Loss: 1.5397\n",
      "Epoch 0, Train Loss: 1.5310\n",
      "Epoch 0, Train Loss: 1.5373\n",
      "Epoch 0, Train Loss: 1.4830\n",
      "Epoch 0, Train Loss: 1.4844\n",
      "Epoch 0, Train Loss: 1.5654\n",
      "Epoch 0, Train Loss: 1.4423\n",
      "Epoch 0, Train Loss: 1.4961\n",
      "Epoch 0, Train Loss: 1.4541\n",
      "Epoch 0, Train Loss: 1.5544\n",
      "Epoch 0, Train Loss: 1.5128\n",
      "Epoch 0, Train Loss: 1.4626\n",
      "Epoch 0, Train Loss: 1.6098\n",
      "Epoch 0, Train Loss: 1.4903\n",
      "Epoch 0, Train Loss: 1.5549\n",
      "Epoch 0, Train Loss: 1.5032\n",
      "Epoch 0, Train Loss: 1.5522\n",
      "Epoch 0, Train Loss: 1.5510\n",
      "Epoch 0, Train Loss: 1.5288\n",
      "Epoch 0, Train Loss: 1.4859\n",
      "Epoch 0, Train Loss: 1.4316\n",
      "Epoch 0, Train Loss: 1.4901\n",
      "Epoch 0, Train Loss: 1.5824\n",
      "Epoch 0, Train Loss: 1.5187\n",
      "Epoch 0, Train Loss: 1.3757\n",
      "Epoch 0, Train Loss: 1.5219\n",
      "Epoch 0, Train Loss: 1.5033\n",
      "Epoch 0, Train Loss: 1.4964\n",
      "Epoch 0, Train Loss: 1.5011\n",
      "Epoch 0, Train Loss: 1.5649\n",
      "Epoch 0, Train Loss: 1.4937\n",
      "Epoch 0, Train Loss: 1.4397\n",
      "Epoch 0, Train Loss: 1.3814\n",
      "Epoch 0, Train Loss: 1.5092\n",
      "Epoch 0, Train Loss: 1.4634\n",
      "Epoch 0, Train Loss: 1.5557\n",
      "Epoch 0, Train Loss: 1.4275\n",
      "Epoch 0, Train Loss: 1.4726\n",
      "Epoch 0, Train Loss: 1.4672\n",
      "Epoch 0, Train Loss: 1.5397\n",
      "Epoch 0, Train Loss: 1.4567\n",
      "Epoch 0, Train Loss: 1.5063\n",
      "Epoch 0, Train Loss: 1.4710\n",
      "Epoch 0, Train Loss: 1.4854\n",
      "Epoch 0, Train Loss: 1.4873\n",
      "Epoch 0, Train Loss: 1.4599\n",
      "Epoch 0, Train Loss: 1.4468\n",
      "Epoch 0, Train Loss: 1.5527\n",
      "Epoch 0, Train Loss: 1.5834\n",
      "Epoch 0, Train Loss: 1.5412\n",
      "Epoch 0, Train Loss: 1.5076\n",
      "Epoch 0, Train Loss: 1.4068\n",
      "Epoch 0, Train Loss: 1.4585\n",
      "Epoch 0, Train Loss: 1.4976\n",
      "Epoch 0, Train Loss: 1.4701\n",
      "Epoch 0, Train Loss: 1.4062\n",
      "Epoch 0, Train Loss: 1.5591\n",
      "Epoch 0, Train Loss: 1.4156\n",
      "Epoch 0, Train Loss: 1.5179\n",
      "Epoch 0, Train Loss: 1.4941\n",
      "Epoch 0, Train Loss: 1.4202\n",
      "Epoch 0, Train Loss: 1.4327\n",
      "Epoch 0, Train Loss: 1.4232\n",
      "Epoch 0, Train Loss: 1.4317\n",
      "Epoch 0, Train Loss: 1.5593\n",
      "Epoch 0, Train Loss: 1.4978\n",
      "Epoch 0, Train Loss: 1.4199\n",
      "Epoch 0, Train Loss: 1.4711\n",
      "Epoch 0, Train Loss: 1.5250\n",
      "Epoch 0, Train Loss: 1.4400\n",
      "Epoch 0, Train Loss: 1.4321\n",
      "Epoch 0, Train Loss: 1.4919\n",
      "Epoch 0, Train Loss: 1.4153\n",
      "Epoch 0, Train Loss: 1.5216\n",
      "Epoch 0, Train Loss: 1.4538\n",
      "Epoch 0, Train Loss: 1.4733\n",
      "Epoch 0, Train Loss: 1.4016\n",
      "Epoch 0, Train Loss: 1.4550\n",
      "Epoch 0, Train Loss: 1.5177\n",
      "Epoch 0, Train Loss: 1.5056\n",
      "Epoch 0, Train Loss: 1.6024\n",
      "Epoch 0, Train Loss: 1.4803\n",
      "Epoch 0, Train Loss: 1.5652\n",
      "Epoch 0, Train Loss: 1.4958\n",
      "Epoch 0, Train Loss: 1.4437\n",
      "Epoch 0, Train Loss: 1.5102\n",
      "Epoch 0, Train Loss: 1.4584\n",
      "Epoch 0, Train Loss: 1.4095\n",
      "Epoch 0, Train Loss: 1.4437\n",
      "Epoch 0, Train Loss: 1.3814\n",
      "Epoch 0, Train Loss: 1.4390\n",
      "Epoch 0, Train Loss: 1.5355\n",
      "Epoch 0, Train Loss: 1.5106\n",
      "Epoch 0, Train Loss: 1.3688\n",
      "Epoch 0, Train Loss: 1.4388\n",
      "Epoch 0, Train Loss: 1.4439\n",
      "Epoch 0, Train Loss: 1.4341\n",
      "Epoch 0, Train Loss: 1.4328\n",
      "Epoch 0, Train Loss: 1.5254\n",
      "Epoch 0, Train Loss: 1.5155\n",
      "Epoch 0, Train Loss: 1.3590\n",
      "Epoch 0, Train Loss: 1.5131\n",
      "Epoch 0, Train Loss: 1.3857\n",
      "Epoch 0, Train Loss: 1.3518\n",
      "Epoch 0, Train Loss: 1.4625\n",
      "Epoch 0, Train Loss: 1.5227\n",
      "Epoch 0, Train Loss: 1.4454\n",
      "Epoch 0, Train Loss: 1.3819\n",
      "Epoch 0, Train Loss: 1.6847\n",
      "Epoch 0, Train Loss: 1.5614\n",
      "Epoch 0, Train Loss: 1.5626\n",
      "Epoch 0, Train Loss: 1.4060\n",
      "Epoch 0, Train Loss: 1.4376\n",
      "Epoch 0, Train Loss: 1.4808\n",
      "Epoch 0, Train Loss: 1.4761\n",
      "Epoch 0, Train Loss: 1.4409\n",
      "Epoch 0, Train Loss: 1.3525\n",
      "Epoch 0, Train Loss: 1.5154\n",
      "Epoch 0, Train Loss: 1.3993\n",
      "Epoch 0, Train Loss: 1.4494\n",
      "Epoch 0, Train Loss: 1.5805\n",
      "Epoch 0, Train Loss: 1.4670\n",
      "Epoch 0, Train Loss: 1.5670\n",
      "Epoch 0, Train Loss: 1.6958\n",
      "Epoch 0, Train Loss: 1.4547\n",
      "Epoch 0, Train Loss: 1.5136\n",
      "Epoch 0, Train Loss: 1.5112\n",
      "Epoch 0, Train Loss: 1.3245\n",
      "Epoch 0, Train Loss: 1.3992\n",
      "Epoch 0, Train Loss: 1.4703\n",
      "Epoch 0, Train Loss: 1.4383\n",
      "Epoch 0, Train Loss: 1.4519\n",
      "Epoch 0, Train Loss: 1.4571\n",
      "Epoch 0, Train Loss: 1.3100\n",
      "Epoch 0, Train Loss: 1.4290\n",
      "Epoch 0, Train Loss: 1.6871\n",
      "Epoch 0, Train Loss: 1.5168\n",
      "Epoch 0, Train Loss: 1.4785\n",
      "Epoch 0, Train Loss: 1.5131\n",
      "Epoch 0, Train Loss: 1.3468\n",
      "Epoch 0, Train Loss: 1.5077\n",
      "Epoch 0, Train Loss: 1.5499\n",
      "Epoch 0, Train Loss: 1.6392\n",
      "Epoch 0, Train Loss: 1.5687\n",
      "Epoch 0, Train Loss: 1.6105\n",
      "Epoch 0, Train Loss: 1.5223\n",
      "Epoch 0, Train Loss: 1.5455\n",
      "Epoch 0, Train Loss: 1.6402\n",
      "Epoch 0, Train Loss: 1.5291\n",
      "Epoch 0, Train Loss: 1.4777\n",
      "Epoch 0, Train Loss: 1.4863\n",
      "Epoch 0, Train Loss: 1.5724\n",
      "Epoch 0, Train Loss: 1.6214\n",
      "Epoch 0, Train Loss: 1.5419\n",
      "Epoch 0, Train Loss: 1.5451\n",
      "Epoch 0, Train Loss: 1.8163\n",
      "Epoch 0, Train Loss: 1.6546\n",
      "Epoch 0, Train Loss: 1.5683\n",
      "Epoch 0, Train Loss: 1.5281\n",
      "Epoch 0, Train Loss: 1.3731\n",
      "Epoch 0, Train Loss: 1.3631\n",
      "Epoch 0, Train Loss: 1.5397\n",
      "Epoch 0, Train Loss: 1.5970\n",
      "Epoch 0, Train Loss: 1.6549\n",
      "Epoch 0, Train Loss: 1.6156\n",
      "Epoch 0, Train Loss: 1.4890\n",
      "Epoch 0, Train Loss: 1.5673\n",
      "Epoch 0, Train Loss: 1.5779\n",
      "Epoch 0, Train Loss: 1.6659\n",
      "Epoch 0, Train Loss: 1.5902\n",
      "Epoch 0, Train Loss: 1.5192\n",
      "Epoch 0, Train Loss: 1.6649\n",
      "Epoch 0, Train Loss: 1.5819\n",
      "Epoch 0, Train Loss: 1.6221\n",
      "Epoch 0, Train Loss: 1.6634\n",
      "Epoch 0, Train Loss: 1.4632\n",
      "Epoch 0, Train Loss: 1.5760\n",
      "Epoch 0, Train Loss: 1.5314\n",
      "Epoch 0, Train Loss: 1.4145\n",
      "Epoch 0, Train Loss: 1.3763\n",
      "Epoch 0, Train Loss: 1.5819\n",
      "Epoch 0, Train Loss: 1.6631\n",
      "Epoch 0, Train Loss: 1.6913\n",
      "Epoch 0, Train Loss: 1.6758\n",
      "Epoch 0, Train Loss: 1.6079\n",
      "Epoch 0, Train Loss: 1.5978\n",
      "Epoch 0, Train Loss: 1.4139\n",
      "Epoch 0, Train Loss: 1.6348\n",
      "Epoch 0, Train Loss: 1.6009\n",
      "Epoch 0, Train Loss: 1.7742\n",
      "Epoch 0, Train Loss: 1.6991\n",
      "Epoch 0, Train Loss: 1.7453\n",
      "Epoch 0, Train Loss: 1.6057\n",
      "Epoch 0, Train Loss: 1.5580\n",
      "Epoch 0, Train Loss: 1.5174\n",
      "Epoch 0, Train Loss: 1.4465\n",
      "Epoch 0, Train Loss: 1.5235\n",
      "Epoch 0, Train Loss: 1.4934\n",
      "Epoch 0, Train Loss: 1.7161\n",
      "Epoch 0, Train Loss: 1.4009\n",
      "Epoch 0, Train Loss: 1.7251\n",
      "Epoch 0, Train Loss: 1.4635\n",
      "Epoch 0, Train Loss: 1.6405\n",
      "Epoch 0, Train Loss: 1.7829\n",
      "Epoch 0, Train Loss: 1.5244\n",
      "Epoch 0, Train Loss: 1.7456\n",
      "Epoch 0, Train Loss: 1.7102\n",
      "Epoch 0, Train Loss: 1.8156\n",
      "Epoch 0, Train Loss: 1.6754\n",
      "Epoch 0, Train Loss: 1.5347\n",
      "Epoch 0, Train Loss: 1.5533\n",
      "Epoch 0, Train Loss: 1.7631\n",
      "Epoch 0, Train Loss: 1.7774\n",
      "Epoch 0, Train Loss: 1.4504\n",
      "Epoch 0, Train Loss: 1.6331\n",
      "Epoch 0, Train Loss: 1.5714\n",
      "Epoch 0, Avg Loss: 1.7503, Acc: 34.91%\n",
      "Epoch 1, Avg Loss: 2.1889, Acc: 36.35%\n",
      "Epoch 2, Train Loss: 2.9434\n",
      "Epoch 2, Train Loss: 3.0999\n",
      "Epoch 2, Train Loss: 3.3897\n",
      "Epoch 2, Train Loss: 3.1154\n",
      "Epoch 2, Train Loss: 2.8027\n",
      "Epoch 2, Train Loss: 2.6418\n",
      "Epoch 2, Train Loss: 2.8844\n",
      "Epoch 2, Train Loss: 2.7874\n",
      "Epoch 2, Train Loss: 3.1391\n",
      "Epoch 2, Train Loss: 2.7742\n",
      "Epoch 2, Train Loss: 3.6093\n",
      "Epoch 2, Train Loss: 2.2990\n",
      "Epoch 2, Train Loss: 3.1212\n",
      "Epoch 2, Train Loss: 2.9353\n",
      "Epoch 2, Train Loss: 3.1847\n",
      "Epoch 2, Train Loss: 3.2450\n",
      "Epoch 2, Train Loss: 3.7986\n",
      "Epoch 2, Train Loss: 3.2180\n",
      "Epoch 2, Train Loss: 2.8156\n",
      "Epoch 2, Train Loss: 3.4285\n",
      "Epoch 2, Train Loss: 2.6466\n",
      "Epoch 2, Train Loss: 2.2902\n",
      "Epoch 2, Train Loss: 3.0456\n",
      "Epoch 2, Train Loss: 3.0301\n",
      "Epoch 2, Train Loss: 2.8728\n",
      "Epoch 2, Train Loss: 2.9310\n",
      "Epoch 2, Train Loss: 3.5691\n",
      "Epoch 2, Train Loss: 3.1182\n",
      "Epoch 2, Train Loss: 2.3692\n",
      "Epoch 2, Train Loss: 3.2974\n",
      "Epoch 2, Train Loss: 2.8414\n",
      "Epoch 2, Train Loss: 3.1515\n",
      "Epoch 2, Train Loss: 3.0507\n",
      "Epoch 2, Train Loss: 2.8493\n",
      "Epoch 2, Train Loss: 2.6808\n",
      "Epoch 2, Train Loss: 3.0628\n",
      "Epoch 2, Train Loss: 2.9347\n",
      "Epoch 2, Train Loss: 2.9173\n",
      "Epoch 2, Train Loss: 2.9073\n",
      "Epoch 2, Train Loss: 2.8377\n",
      "Epoch 2, Train Loss: 2.8414\n",
      "Epoch 2, Train Loss: 3.3936\n",
      "Epoch 2, Train Loss: 2.8664\n",
      "Epoch 2, Train Loss: 2.8919\n",
      "Epoch 2, Train Loss: 3.3230\n",
      "Epoch 2, Train Loss: 3.4281\n",
      "Epoch 2, Train Loss: 3.6484\n",
      "Epoch 2, Train Loss: 3.3344\n",
      "Epoch 2, Train Loss: 3.4417\n",
      "Epoch 2, Train Loss: 3.0177\n",
      "Epoch 2, Train Loss: 3.3989\n",
      "Epoch 2, Train Loss: 2.7590\n",
      "Epoch 2, Train Loss: 3.5094\n",
      "Epoch 2, Train Loss: 2.9002\n",
      "Epoch 2, Train Loss: 2.4523\n",
      "Epoch 2, Train Loss: 3.1870\n",
      "Epoch 2, Train Loss: 3.9959\n",
      "Epoch 2, Train Loss: 3.4972\n",
      "Epoch 2, Train Loss: 2.9097\n",
      "Epoch 2, Train Loss: 2.4293\n",
      "Epoch 2, Train Loss: 3.6518\n",
      "Epoch 2, Train Loss: 3.3292\n",
      "Epoch 2, Train Loss: 2.7658\n",
      "Epoch 2, Train Loss: 3.4272\n",
      "Epoch 2, Train Loss: 2.8110\n",
      "Epoch 2, Train Loss: 3.0346\n",
      "Epoch 2, Train Loss: 2.7737\n",
      "Epoch 2, Train Loss: 3.3932\n",
      "Epoch 2, Train Loss: 3.5252\n",
      "Epoch 2, Train Loss: 2.9967\n",
      "Epoch 2, Train Loss: 2.6453\n",
      "Epoch 2, Train Loss: 2.2238\n",
      "Epoch 2, Train Loss: 2.8305\n",
      "Epoch 2, Train Loss: 3.3358\n",
      "Epoch 2, Train Loss: 3.4690\n",
      "Epoch 2, Train Loss: 2.9906\n",
      "Epoch 2, Train Loss: 2.8209\n",
      "Epoch 2, Train Loss: 3.2724\n",
      "Epoch 2, Train Loss: 3.6409\n",
      "Epoch 2, Train Loss: 2.5985\n",
      "Epoch 2, Train Loss: 2.5556\n",
      "Epoch 2, Train Loss: 3.0668\n",
      "Epoch 2, Train Loss: 3.4212\n",
      "Epoch 2, Train Loss: 3.5428\n",
      "Epoch 2, Train Loss: 3.0552\n",
      "Epoch 2, Train Loss: 3.3370\n",
      "Epoch 2, Train Loss: 2.6846\n",
      "Epoch 2, Train Loss: 3.7364\n",
      "Epoch 2, Train Loss: 3.7422\n",
      "Epoch 2, Train Loss: 3.0122\n",
      "Epoch 2, Train Loss: 3.4563\n",
      "Epoch 2, Train Loss: 3.7946\n",
      "Epoch 2, Train Loss: 3.7366\n",
      "Epoch 2, Train Loss: 3.6780\n",
      "Epoch 2, Train Loss: 3.5367\n",
      "Epoch 2, Train Loss: 3.4823\n",
      "Epoch 2, Train Loss: 3.8911\n",
      "Epoch 2, Train Loss: 3.2255\n",
      "Epoch 2, Train Loss: 3.2037\n",
      "Epoch 2, Train Loss: 3.3357\n",
      "Epoch 2, Train Loss: 3.9300\n",
      "Epoch 2, Train Loss: 3.9456\n",
      "Epoch 2, Train Loss: 3.8187\n",
      "Epoch 2, Train Loss: 3.3683\n",
      "Epoch 2, Train Loss: 3.3737\n",
      "Epoch 2, Train Loss: 2.4380\n",
      "Epoch 2, Train Loss: 4.1778\n",
      "Epoch 2, Train Loss: 3.2541\n",
      "Epoch 2, Train Loss: 3.0195\n",
      "Epoch 2, Train Loss: 3.1432\n",
      "Epoch 2, Train Loss: 2.8345\n",
      "Epoch 2, Train Loss: 3.3959\n",
      "Epoch 2, Train Loss: 3.2375\n",
      "Epoch 2, Train Loss: 3.0506\n",
      "Epoch 2, Train Loss: 3.2406\n",
      "Epoch 2, Train Loss: 2.9824\n",
      "Epoch 2, Train Loss: 3.4536\n",
      "Epoch 2, Train Loss: 3.2312\n",
      "Epoch 2, Train Loss: 3.0940\n",
      "Epoch 2, Train Loss: 3.0985\n",
      "Epoch 2, Train Loss: 4.2378\n",
      "Epoch 2, Train Loss: 3.6055\n",
      "Epoch 2, Train Loss: 4.4234\n",
      "Epoch 2, Train Loss: 4.4427\n",
      "Epoch 2, Train Loss: 3.7572\n",
      "Epoch 2, Train Loss: 3.0537\n",
      "Epoch 2, Train Loss: 3.0412\n",
      "Epoch 2, Train Loss: 3.0247\n",
      "Epoch 2, Train Loss: 2.5346\n",
      "Epoch 2, Train Loss: 3.8992\n",
      "Epoch 2, Train Loss: 2.6553\n",
      "Epoch 2, Train Loss: 3.2044\n",
      "Epoch 2, Train Loss: 3.0205\n",
      "Epoch 2, Train Loss: 3.1178\n",
      "Epoch 2, Train Loss: 3.7937\n",
      "Epoch 2, Train Loss: 2.9570\n",
      "Epoch 2, Train Loss: 3.9738\n",
      "Epoch 2, Train Loss: 3.5552\n",
      "Epoch 2, Train Loss: 3.2516\n",
      "Epoch 2, Train Loss: 3.3117\n",
      "Epoch 2, Train Loss: 3.1079\n",
      "Epoch 2, Train Loss: 2.6494\n",
      "Epoch 2, Train Loss: 3.9463\n",
      "Epoch 2, Train Loss: 2.8356\n",
      "Epoch 2, Train Loss: 3.2563\n",
      "Epoch 2, Train Loss: 3.2025\n",
      "Epoch 2, Train Loss: 4.2565\n",
      "Epoch 2, Train Loss: 5.2278\n",
      "Epoch 2, Train Loss: 3.5746\n",
      "Epoch 2, Train Loss: 3.9165\n",
      "Epoch 2, Train Loss: 3.5550\n",
      "Epoch 2, Train Loss: 3.3311\n",
      "Epoch 2, Train Loss: 3.3136\n",
      "Epoch 2, Train Loss: 3.5029\n",
      "Epoch 2, Train Loss: 3.8534\n",
      "Epoch 2, Train Loss: 3.4151\n",
      "Epoch 2, Train Loss: 4.0173\n",
      "Epoch 2, Train Loss: 3.9036\n",
      "Epoch 2, Train Loss: 4.0991\n",
      "Epoch 2, Train Loss: 3.2738\n",
      "Epoch 2, Train Loss: 3.5470\n",
      "Epoch 2, Train Loss: 2.4604\n",
      "Epoch 2, Train Loss: 3.3289\n",
      "Epoch 2, Train Loss: 2.8825\n",
      "Epoch 2, Train Loss: 3.9687\n",
      "Epoch 2, Train Loss: 3.9967\n",
      "Epoch 2, Train Loss: 4.0270\n",
      "Epoch 2, Train Loss: 2.5019\n",
      "Epoch 2, Train Loss: 2.3535\n",
      "Epoch 2, Train Loss: 3.2076\n",
      "Epoch 2, Train Loss: 3.8249\n",
      "Epoch 2, Train Loss: 3.3303\n",
      "Epoch 2, Train Loss: 3.7096\n",
      "Epoch 2, Train Loss: 3.2112\n",
      "Epoch 2, Train Loss: 4.3805\n",
      "Epoch 2, Train Loss: 4.1282\n",
      "Epoch 2, Train Loss: 3.0180\n",
      "Epoch 2, Train Loss: 3.5570\n",
      "Epoch 2, Train Loss: 3.2092\n",
      "Epoch 2, Train Loss: 3.3139\n",
      "Epoch 2, Train Loss: 3.6892\n",
      "Epoch 2, Train Loss: 3.8846\n",
      "Epoch 2, Train Loss: 3.3189\n",
      "Epoch 2, Train Loss: 3.7975\n",
      "Epoch 2, Train Loss: 3.3938\n",
      "Epoch 2, Train Loss: 2.7787\n",
      "Epoch 2, Train Loss: 3.5129\n",
      "Epoch 2, Train Loss: 4.6762\n",
      "Epoch 2, Train Loss: 2.8092\n",
      "Epoch 2, Train Loss: 3.4258\n",
      "Epoch 2, Train Loss: 3.2696\n",
      "Epoch 2, Train Loss: 3.4016\n",
      "Epoch 2, Train Loss: 3.4097\n",
      "Epoch 2, Train Loss: 3.6312\n",
      "Epoch 2, Train Loss: 3.2614\n",
      "Epoch 2, Train Loss: 3.1047\n",
      "Epoch 2, Train Loss: 3.9585\n",
      "Epoch 2, Train Loss: 3.1423\n",
      "Epoch 2, Train Loss: 2.9630\n",
      "Epoch 2, Train Loss: 3.8321\n",
      "Epoch 2, Train Loss: 3.7552\n",
      "Epoch 2, Train Loss: 3.3386\n",
      "Epoch 2, Train Loss: 3.8280\n",
      "Epoch 2, Train Loss: 3.5353\n",
      "Epoch 2, Train Loss: 2.2042\n",
      "Epoch 2, Train Loss: 4.5797\n",
      "Epoch 2, Train Loss: 4.0206\n",
      "Epoch 2, Train Loss: 3.6350\n",
      "Epoch 2, Train Loss: 3.6458\n",
      "Epoch 2, Train Loss: 3.7997\n",
      "Epoch 2, Train Loss: 3.5085\n",
      "Epoch 2, Train Loss: 3.8695\n",
      "Epoch 2, Train Loss: 4.1849\n",
      "Epoch 2, Train Loss: 4.5009\n",
      "Epoch 2, Train Loss: 2.8015\n",
      "Epoch 2, Train Loss: 4.0228\n",
      "Epoch 2, Train Loss: 3.8481\n",
      "Epoch 2, Train Loss: 3.7723\n",
      "Epoch 2, Train Loss: 3.3332\n",
      "Epoch 2, Train Loss: 3.9991\n",
      "Epoch 2, Train Loss: 2.9018\n",
      "Epoch 2, Train Loss: 3.6087\n",
      "Epoch 2, Train Loss: 3.1657\n",
      "Epoch 2, Train Loss: 3.7331\n",
      "Epoch 2, Train Loss: 3.2408\n",
      "Epoch 2, Train Loss: 4.0727\n",
      "Epoch 2, Train Loss: 4.7392\n",
      "Epoch 2, Train Loss: 4.3700\n",
      "Epoch 2, Train Loss: 4.2870\n",
      "Epoch 2, Train Loss: 3.0389\n",
      "Epoch 2, Train Loss: 3.5568\n",
      "Epoch 2, Train Loss: 4.3196\n",
      "Epoch 2, Train Loss: 3.9785\n",
      "Epoch 2, Train Loss: 3.9243\n",
      "Epoch 2, Train Loss: 3.2935\n",
      "Epoch 2, Train Loss: 3.6253\n",
      "Epoch 2, Train Loss: 3.5764\n",
      "Epoch 2, Train Loss: 3.6550\n",
      "Epoch 2, Train Loss: 4.3804\n",
      "Epoch 2, Train Loss: 3.8176\n",
      "Epoch 2, Train Loss: 3.1581\n",
      "Epoch 2, Train Loss: 3.8329\n",
      "Epoch 2, Train Loss: 3.6899\n",
      "Epoch 2, Train Loss: 3.9655\n",
      "Epoch 2, Train Loss: 4.2852\n",
      "Epoch 2, Train Loss: 3.4272\n",
      "Epoch 2, Train Loss: 4.4681\n",
      "Epoch 2, Train Loss: 4.1289\n",
      "Epoch 2, Train Loss: 4.0718\n",
      "Epoch 2, Train Loss: 4.9421\n",
      "Epoch 2, Train Loss: 4.0160\n",
      "Epoch 2, Train Loss: 3.2107\n",
      "Epoch 2, Train Loss: 3.3340\n",
      "Epoch 2, Train Loss: 4.5160\n",
      "Epoch 2, Train Loss: 4.6201\n",
      "Epoch 2, Train Loss: 4.0732\n",
      "Epoch 2, Train Loss: 4.2277\n",
      "Epoch 2, Train Loss: 4.8795\n",
      "Epoch 2, Train Loss: 3.5427\n",
      "Epoch 2, Train Loss: 3.9017\n",
      "Epoch 2, Train Loss: 3.3072\n",
      "Epoch 2, Train Loss: 3.1270\n",
      "Epoch 2, Train Loss: 4.9819\n",
      "Epoch 2, Train Loss: 4.4013\n",
      "Epoch 2, Train Loss: 3.0882\n",
      "Epoch 2, Train Loss: 4.0552\n",
      "Epoch 2, Train Loss: 4.0265\n",
      "Epoch 2, Train Loss: 4.1015\n",
      "Epoch 2, Train Loss: 4.3138\n",
      "Epoch 2, Train Loss: 2.9987\n",
      "Epoch 2, Train Loss: 4.2477\n",
      "Epoch 2, Train Loss: 3.8434\n",
      "Epoch 2, Train Loss: 3.7275\n",
      "Epoch 2, Train Loss: 4.5033\n",
      "Epoch 2, Train Loss: 3.5004\n",
      "Epoch 2, Train Loss: 4.2741\n",
      "Epoch 2, Train Loss: 3.7968\n",
      "Epoch 2, Train Loss: 3.9671\n",
      "Epoch 2, Train Loss: 3.2382\n",
      "Epoch 2, Train Loss: 4.1136\n",
      "Epoch 2, Train Loss: 3.5752\n",
      "Epoch 2, Train Loss: 4.8922\n",
      "Epoch 2, Train Loss: 4.2408\n",
      "Epoch 2, Train Loss: 3.1224\n",
      "Epoch 2, Train Loss: 4.8512\n",
      "Epoch 2, Train Loss: 4.3126\n",
      "Epoch 2, Train Loss: 3.8407\n",
      "Epoch 2, Train Loss: 2.5976\n",
      "Epoch 2, Train Loss: 3.4711\n",
      "Epoch 2, Train Loss: 3.6661\n",
      "Epoch 2, Train Loss: 3.5535\n",
      "Epoch 2, Train Loss: 5.0047\n",
      "Epoch 2, Train Loss: 3.4003\n",
      "Epoch 2, Train Loss: 3.9800\n",
      "Epoch 2, Train Loss: 3.7508\n",
      "Epoch 2, Train Loss: 4.5301\n",
      "Epoch 2, Train Loss: 4.3033\n",
      "Epoch 2, Train Loss: 3.8476\n",
      "Epoch 2, Train Loss: 4.0795\n",
      "Epoch 2, Train Loss: 3.7705\n",
      "Epoch 2, Train Loss: 4.8389\n",
      "Epoch 2, Train Loss: 4.7165\n",
      "Epoch 2, Train Loss: 2.8581\n",
      "Epoch 2, Train Loss: 4.7904\n",
      "Epoch 2, Train Loss: 4.0706\n",
      "Epoch 2, Train Loss: 4.2393\n",
      "Epoch 2, Train Loss: 4.0312\n",
      "Epoch 2, Train Loss: 3.7090\n",
      "Epoch 2, Train Loss: 3.7047\n",
      "Epoch 2, Train Loss: 3.5161\n",
      "Epoch 2, Train Loss: 4.4568\n",
      "Epoch 2, Train Loss: 4.1850\n",
      "Epoch 2, Train Loss: 4.0454\n",
      "Epoch 2, Train Loss: 3.7381\n",
      "Epoch 2, Train Loss: 4.1651\n",
      "Epoch 2, Train Loss: 3.9946\n",
      "Epoch 2, Train Loss: 3.1639\n",
      "Epoch 2, Train Loss: 3.6132\n",
      "Epoch 2, Train Loss: 3.7042\n",
      "Epoch 2, Train Loss: 3.1942\n",
      "Epoch 2, Train Loss: 5.0127\n",
      "Epoch 2, Train Loss: 3.9754\n",
      "Epoch 2, Train Loss: 4.8916\n",
      "Epoch 2, Train Loss: 4.5282\n",
      "Epoch 2, Train Loss: 3.6460\n",
      "Epoch 2, Train Loss: 4.5895\n",
      "Epoch 2, Train Loss: 4.9425\n",
      "Epoch 2, Train Loss: 3.9824\n",
      "Epoch 2, Train Loss: 4.5894\n",
      "Epoch 2, Train Loss: 4.2914\n",
      "Epoch 2, Train Loss: 4.1638\n",
      "Epoch 2, Train Loss: 4.1129\n",
      "Epoch 2, Train Loss: 5.0031\n",
      "Epoch 2, Train Loss: 2.7636\n",
      "Epoch 2, Train Loss: 4.4651\n",
      "Epoch 2, Train Loss: 3.9535\n",
      "Epoch 2, Train Loss: 3.3306\n",
      "Epoch 2, Train Loss: 4.0215\n",
      "Epoch 2, Train Loss: 3.6794\n",
      "Epoch 2, Train Loss: 4.4881\n",
      "Epoch 2, Train Loss: 3.4770\n",
      "Epoch 2, Train Loss: 4.3920\n",
      "Epoch 2, Train Loss: 2.9414\n",
      "Epoch 2, Train Loss: 5.2581\n",
      "Epoch 2, Train Loss: 4.2553\n",
      "Epoch 2, Train Loss: 3.5561\n",
      "Epoch 2, Train Loss: 4.3466\n",
      "Epoch 2, Train Loss: 4.8015\n",
      "Epoch 2, Train Loss: 4.1535\n",
      "Epoch 2, Train Loss: 4.6140\n",
      "Epoch 2, Train Loss: 5.3496\n",
      "Epoch 2, Train Loss: 4.4700\n",
      "Epoch 2, Train Loss: 3.9974\n",
      "Epoch 2, Train Loss: 3.1698\n",
      "Epoch 2, Train Loss: 4.1827\n",
      "Epoch 2, Train Loss: 4.6448\n",
      "Epoch 2, Train Loss: 4.0649\n",
      "Epoch 2, Train Loss: 4.7296\n",
      "Epoch 2, Train Loss: 3.5782\n",
      "Epoch 2, Train Loss: 3.4912\n",
      "Epoch 2, Train Loss: 5.6085\n",
      "Epoch 2, Train Loss: 3.8227\n",
      "Epoch 2, Train Loss: 4.5478\n",
      "Epoch 2, Train Loss: 4.8575\n",
      "Epoch 2, Train Loss: 4.7485\n",
      "Epoch 2, Train Loss: 4.4636\n",
      "Epoch 2, Train Loss: 3.5911\n",
      "Epoch 2, Train Loss: 4.3737\n",
      "Epoch 2, Train Loss: 3.6800\n",
      "Epoch 2, Train Loss: 4.1852\n",
      "Epoch 2, Train Loss: 5.1608\n",
      "Epoch 2, Train Loss: 3.9301\n",
      "Epoch 2, Train Loss: 4.7057\n",
      "Epoch 2, Train Loss: 5.0363\n",
      "Epoch 2, Train Loss: 4.5042\n",
      "Epoch 2, Train Loss: 4.0495\n",
      "Epoch 2, Train Loss: 4.3280\n",
      "Epoch 2, Train Loss: 5.0224\n",
      "Epoch 2, Train Loss: 4.4154\n",
      "Epoch 2, Train Loss: 3.9658\n",
      "Epoch 2, Train Loss: 3.7906\n",
      "Epoch 2, Train Loss: 3.9492\n",
      "Epoch 2, Train Loss: 3.1931\n",
      "Epoch 2, Train Loss: 4.5871\n",
      "Epoch 2, Train Loss: 4.3060\n",
      "Epoch 2, Train Loss: 4.2665\n",
      "Epoch 2, Train Loss: 3.7469\n",
      "Epoch 2, Train Loss: 4.9956\n",
      "Epoch 2, Train Loss: 4.0659\n",
      "Epoch 2, Train Loss: 3.7724\n",
      "Epoch 2, Train Loss: 5.0541\n",
      "Epoch 2, Train Loss: 4.7810\n",
      "Epoch 2, Train Loss: 3.8128\n",
      "Epoch 2, Train Loss: 6.5772\n",
      "Epoch 2, Train Loss: 4.6967\n",
      "Epoch 2, Train Loss: 3.6827\n",
      "Epoch 2, Train Loss: 4.2928\n",
      "Epoch 2, Train Loss: 4.3500\n",
      "Epoch 2, Train Loss: 3.8657\n",
      "Epoch 2, Train Loss: 4.6900\n",
      "Epoch 2, Train Loss: 4.2597\n",
      "Epoch 2, Train Loss: 4.2888\n",
      "Epoch 2, Train Loss: 3.9492\n",
      "Epoch 2, Train Loss: 4.4779\n",
      "Epoch 2, Train Loss: 4.2577\n",
      "Epoch 2, Train Loss: 3.7319\n",
      "Epoch 2, Train Loss: 4.6134\n",
      "Epoch 2, Train Loss: 5.3524\n",
      "Epoch 2, Train Loss: 5.2828\n",
      "Epoch 2, Train Loss: 4.2959\n",
      "Epoch 2, Train Loss: 4.8670\n",
      "Epoch 2, Train Loss: 4.4815\n",
      "Epoch 2, Train Loss: 4.1405\n",
      "Epoch 2, Train Loss: 5.3151\n",
      "Epoch 2, Train Loss: 3.6648\n",
      "Epoch 2, Train Loss: 4.1168\n",
      "Epoch 2, Train Loss: 6.2048\n",
      "Epoch 2, Train Loss: 3.9991\n",
      "Epoch 2, Train Loss: 5.3510\n",
      "Epoch 2, Train Loss: 3.9025\n",
      "Epoch 2, Train Loss: 4.9147\n",
      "Epoch 2, Train Loss: 4.8891\n",
      "Epoch 2, Train Loss: 5.5945\n",
      "Epoch 2, Train Loss: 5.1404\n",
      "Epoch 2, Train Loss: 5.0965\n",
      "Epoch 2, Train Loss: 4.4774\n",
      "Epoch 2, Train Loss: 3.6607\n",
      "Epoch 2, Train Loss: 4.2230\n",
      "Epoch 2, Train Loss: 5.4487\n",
      "Epoch 2, Train Loss: 4.6417\n",
      "Epoch 2, Train Loss: 4.0932\n",
      "Epoch 2, Train Loss: 4.8217\n",
      "Epoch 2, Train Loss: 5.4517\n",
      "Epoch 2, Train Loss: 5.9077\n",
      "Epoch 2, Train Loss: 4.7334\n",
      "Epoch 2, Train Loss: 4.8726\n",
      "Epoch 2, Train Loss: 4.2025\n",
      "Epoch 2, Train Loss: 3.8936\n",
      "Epoch 2, Train Loss: 4.1330\n",
      "Epoch 2, Train Loss: 6.1649\n",
      "Epoch 2, Train Loss: 3.6305\n",
      "Epoch 2, Train Loss: 5.4122\n",
      "Epoch 2, Train Loss: 4.9113\n",
      "Epoch 2, Train Loss: 4.8738\n",
      "Epoch 2, Train Loss: 3.7782\n",
      "Epoch 2, Train Loss: 4.5213\n",
      "Epoch 2, Train Loss: 4.1432\n",
      "Epoch 2, Train Loss: 4.6000\n",
      "Epoch 2, Train Loss: 5.2391\n",
      "Epoch 2, Train Loss: 3.4021\n",
      "Epoch 2, Train Loss: 4.3110\n",
      "Epoch 2, Train Loss: 4.9264\n",
      "Epoch 2, Train Loss: 3.0972\n",
      "Epoch 2, Train Loss: 4.4357\n",
      "Epoch 2, Train Loss: 5.3042\n",
      "Epoch 2, Train Loss: 5.1783\n",
      "Epoch 2, Train Loss: 4.4409\n",
      "Epoch 2, Train Loss: 4.9206\n",
      "Epoch 2, Train Loss: 4.2171\n",
      "Epoch 2, Train Loss: 4.6230\n",
      "Epoch 2, Train Loss: 4.7179\n",
      "Epoch 2, Train Loss: 4.1005\n",
      "Epoch 2, Train Loss: 4.9923\n",
      "Epoch 2, Train Loss: 4.4906\n",
      "Epoch 2, Train Loss: 5.0325\n",
      "Epoch 2, Train Loss: 4.8672\n",
      "Epoch 2, Train Loss: 4.4390\n",
      "Epoch 2, Train Loss: 5.0974\n",
      "Epoch 2, Train Loss: 4.4711\n",
      "Epoch 2, Avg Loss: 3.8031, Acc: 37.02%\n",
      "Epoch 3, Avg Loss: 5.5205, Acc: 36.80%\n",
      "Epoch 4, Train Loss: 4.4295\n",
      "Epoch 4, Train Loss: 5.7847\n",
      "Epoch 4, Train Loss: 6.5571\n",
      "Epoch 4, Train Loss: 6.3201\n",
      "Epoch 4, Train Loss: 6.9043\n",
      "Epoch 4, Train Loss: 7.3694\n",
      "Epoch 4, Train Loss: 6.4101\n",
      "Epoch 4, Train Loss: 5.6672\n",
      "Epoch 4, Train Loss: 6.5028\n",
      "Epoch 4, Train Loss: 7.2318\n",
      "Epoch 4, Train Loss: 5.2112\n",
      "Epoch 4, Train Loss: 5.1656\n",
      "Epoch 4, Train Loss: 6.0517\n",
      "Epoch 4, Train Loss: 6.5891\n",
      "Epoch 4, Train Loss: 6.1597\n",
      "Epoch 4, Train Loss: 6.4417\n",
      "Epoch 4, Train Loss: 7.1406\n",
      "Epoch 4, Train Loss: 7.0272\n",
      "Epoch 4, Train Loss: 7.0084\n",
      "Epoch 4, Train Loss: 6.9166\n",
      "Epoch 4, Train Loss: 6.7051\n",
      "Epoch 4, Train Loss: 5.6508\n",
      "Epoch 4, Train Loss: 6.2591\n",
      "Epoch 4, Train Loss: 6.7699\n",
      "Epoch 4, Train Loss: 6.6692\n",
      "Epoch 4, Train Loss: 7.5687\n",
      "Epoch 4, Train Loss: 4.9406\n",
      "Epoch 4, Train Loss: 6.2103\n",
      "Epoch 4, Train Loss: 5.2942\n",
      "Epoch 4, Train Loss: 6.1420\n",
      "Epoch 4, Train Loss: 5.8818\n",
      "Epoch 4, Train Loss: 5.7920\n",
      "Epoch 4, Train Loss: 5.9912\n",
      "Epoch 4, Train Loss: 6.1972\n",
      "Epoch 4, Train Loss: 5.7313\n",
      "Epoch 4, Train Loss: 6.6689\n",
      "Epoch 4, Train Loss: 6.9270\n",
      "Epoch 4, Train Loss: 6.6257\n",
      "Epoch 4, Train Loss: 5.3254\n",
      "Epoch 4, Train Loss: 7.1328\n",
      "Epoch 4, Train Loss: 5.8256\n",
      "Epoch 4, Train Loss: 5.2003\n",
      "Epoch 4, Train Loss: 6.1195\n",
      "Epoch 4, Train Loss: 6.5581\n",
      "Epoch 4, Train Loss: 6.4236\n",
      "Epoch 4, Train Loss: 6.1469\n",
      "Epoch 4, Train Loss: 5.3995\n",
      "Epoch 4, Train Loss: 6.8183\n",
      "Epoch 4, Train Loss: 7.6691\n",
      "Epoch 4, Train Loss: 5.9559\n",
      "Epoch 4, Train Loss: 6.9342\n",
      "Epoch 4, Train Loss: 5.4769\n",
      "Epoch 4, Train Loss: 6.7681\n",
      "Epoch 4, Train Loss: 6.6622\n",
      "Epoch 4, Train Loss: 6.2024\n",
      "Epoch 4, Train Loss: 7.2840\n",
      "Epoch 4, Train Loss: 5.6919\n",
      "Epoch 4, Train Loss: 5.6048\n",
      "Epoch 4, Train Loss: 7.4956\n",
      "Epoch 4, Train Loss: 4.9031\n",
      "Epoch 4, Train Loss: 7.6030\n",
      "Epoch 4, Train Loss: 6.1785\n",
      "Epoch 4, Train Loss: 9.2215\n",
      "Epoch 4, Train Loss: 6.7193\n",
      "Epoch 4, Train Loss: 5.7443\n",
      "Epoch 4, Train Loss: 6.8752\n",
      "Epoch 4, Train Loss: 6.6080\n",
      "Epoch 4, Train Loss: 5.9426\n",
      "Epoch 4, Train Loss: 6.6492\n",
      "Epoch 4, Train Loss: 8.0570\n",
      "Epoch 4, Train Loss: 7.2399\n",
      "Epoch 4, Train Loss: 6.0618\n",
      "Epoch 4, Train Loss: 5.4449\n",
      "Epoch 4, Train Loss: 6.1768\n",
      "Epoch 4, Train Loss: 6.7489\n",
      "Epoch 4, Train Loss: 6.6760\n",
      "Epoch 4, Train Loss: 6.6718\n",
      "Epoch 4, Train Loss: 6.6957\n",
      "Epoch 4, Train Loss: 5.8730\n",
      "Epoch 4, Train Loss: 5.5520\n",
      "Epoch 4, Train Loss: 7.3142\n",
      "Epoch 4, Train Loss: 5.1561\n",
      "Epoch 4, Train Loss: 6.4277\n",
      "Epoch 4, Train Loss: 7.8314\n",
      "Epoch 4, Train Loss: 7.8140\n",
      "Epoch 4, Train Loss: 6.9237\n",
      "Epoch 4, Train Loss: 6.4910\n",
      "Epoch 4, Train Loss: 6.4765\n",
      "Epoch 4, Train Loss: 6.7106\n",
      "Epoch 4, Train Loss: 6.5802\n",
      "Epoch 4, Train Loss: 6.7439\n",
      "Epoch 4, Train Loss: 6.1424\n",
      "Epoch 4, Train Loss: 5.7824\n",
      "Epoch 4, Train Loss: 5.7980\n",
      "Epoch 4, Train Loss: 8.2593\n",
      "Epoch 4, Train Loss: 7.1397\n",
      "Epoch 4, Train Loss: 5.8106\n",
      "Epoch 4, Train Loss: 7.5964\n",
      "Epoch 4, Train Loss: 7.2716\n",
      "Epoch 4, Train Loss: 4.9933\n",
      "Epoch 4, Train Loss: 6.2073\n",
      "Epoch 4, Train Loss: 6.6647\n",
      "Epoch 4, Train Loss: 5.7509\n",
      "Epoch 4, Train Loss: 7.3652\n",
      "Epoch 4, Train Loss: 6.7491\n",
      "Epoch 4, Train Loss: 7.9262\n",
      "Epoch 4, Train Loss: 8.1008\n",
      "Epoch 4, Train Loss: 6.3257\n",
      "Epoch 4, Train Loss: 7.7702\n",
      "Epoch 4, Train Loss: 6.8541\n",
      "Epoch 4, Train Loss: 6.7636\n",
      "Epoch 4, Train Loss: 6.9079\n",
      "Epoch 4, Train Loss: 7.0171\n",
      "Epoch 4, Train Loss: 6.5819\n",
      "Epoch 4, Train Loss: 6.0267\n",
      "Epoch 4, Train Loss: 5.7670\n",
      "Epoch 4, Train Loss: 6.6742\n",
      "Epoch 4, Train Loss: 4.2406\n",
      "Epoch 4, Train Loss: 8.5791\n",
      "Epoch 4, Train Loss: 5.4494\n",
      "Epoch 4, Train Loss: 8.7412\n",
      "Epoch 4, Train Loss: 7.2289\n",
      "Epoch 4, Train Loss: 6.3364\n",
      "Epoch 4, Train Loss: 6.1534\n",
      "Epoch 4, Train Loss: 6.8547\n",
      "Epoch 4, Train Loss: 5.9804\n",
      "Epoch 4, Train Loss: 5.2164\n",
      "Epoch 4, Train Loss: 5.5469\n",
      "Epoch 4, Train Loss: 5.6055\n",
      "Epoch 4, Train Loss: 7.6845\n",
      "Epoch 4, Train Loss: 5.6541\n",
      "Epoch 4, Train Loss: 7.5604\n",
      "Epoch 4, Train Loss: 5.9628\n",
      "Epoch 4, Train Loss: 6.5621\n",
      "Epoch 4, Train Loss: 6.0066\n",
      "Epoch 4, Train Loss: 6.4038\n",
      "Epoch 4, Train Loss: 5.7240\n",
      "Epoch 4, Train Loss: 7.2832\n",
      "Epoch 4, Train Loss: 6.7408\n",
      "Epoch 4, Train Loss: 5.8337\n",
      "Epoch 4, Train Loss: 7.0169\n",
      "Epoch 4, Train Loss: 6.8544\n",
      "Epoch 4, Train Loss: 6.8620\n",
      "Epoch 4, Train Loss: 6.0544\n",
      "Epoch 4, Train Loss: 8.1443\n",
      "Epoch 4, Train Loss: 6.2384\n",
      "Epoch 4, Train Loss: 6.5015\n",
      "Epoch 4, Train Loss: 6.8689\n",
      "Epoch 4, Train Loss: 7.3056\n",
      "Epoch 4, Train Loss: 6.2902\n",
      "Epoch 4, Train Loss: 5.4806\n",
      "Epoch 4, Train Loss: 8.0282\n",
      "Epoch 4, Train Loss: 7.3802\n",
      "Epoch 4, Train Loss: 7.8676\n",
      "Epoch 4, Train Loss: 8.0354\n",
      "Epoch 4, Train Loss: 7.0654\n",
      "Epoch 4, Train Loss: 6.0647\n",
      "Epoch 4, Train Loss: 7.0759\n",
      "Epoch 4, Train Loss: 6.0122\n",
      "Epoch 4, Train Loss: 6.9255\n",
      "Epoch 4, Train Loss: 6.4552\n",
      "Epoch 4, Train Loss: 5.9013\n",
      "Epoch 4, Train Loss: 6.8524\n",
      "Epoch 4, Train Loss: 5.5921\n",
      "Epoch 4, Train Loss: 6.5451\n",
      "Epoch 4, Train Loss: 6.6902\n",
      "Epoch 4, Train Loss: 6.8860\n",
      "Epoch 4, Train Loss: 7.2877\n",
      "Epoch 4, Train Loss: 6.0778\n",
      "Epoch 4, Train Loss: 6.5846\n",
      "Epoch 4, Train Loss: 7.0833\n",
      "Epoch 4, Train Loss: 6.6343\n",
      "Epoch 4, Train Loss: 8.5116\n",
      "Epoch 4, Train Loss: 6.8991\n",
      "Epoch 4, Train Loss: 7.4501\n",
      "Epoch 4, Train Loss: 7.5485\n",
      "Epoch 4, Train Loss: 5.4010\n",
      "Epoch 4, Train Loss: 8.2797\n",
      "Epoch 4, Train Loss: 5.0937\n",
      "Epoch 4, Train Loss: 5.9359\n",
      "Epoch 4, Train Loss: 5.9545\n",
      "Epoch 4, Train Loss: 6.5030\n",
      "Epoch 4, Train Loss: 5.6829\n",
      "Epoch 4, Train Loss: 4.8201\n",
      "Epoch 4, Train Loss: 6.5608\n",
      "Epoch 4, Train Loss: 6.2786\n",
      "Epoch 4, Train Loss: 6.9814\n",
      "Epoch 4, Train Loss: 7.2898\n",
      "Epoch 4, Train Loss: 5.9663\n",
      "Epoch 4, Train Loss: 7.6931\n",
      "Epoch 4, Train Loss: 8.3663\n",
      "Epoch 4, Train Loss: 7.1965\n",
      "Epoch 4, Train Loss: 7.3378\n",
      "Epoch 4, Train Loss: 7.9701\n",
      "Epoch 4, Train Loss: 8.3256\n",
      "Epoch 4, Train Loss: 7.2641\n",
      "Epoch 4, Train Loss: 8.3830\n",
      "Epoch 4, Train Loss: 5.6339\n",
      "Epoch 4, Train Loss: 7.7943\n",
      "Epoch 4, Train Loss: 7.6053\n",
      "Epoch 4, Train Loss: 6.1574\n",
      "Epoch 4, Train Loss: 7.7923\n",
      "Epoch 4, Train Loss: 5.9385\n",
      "Epoch 4, Train Loss: 6.5991\n",
      "Epoch 4, Train Loss: 7.6110\n",
      "Epoch 4, Train Loss: 6.9460\n",
      "Epoch 4, Train Loss: 5.8208\n",
      "Epoch 4, Train Loss: 6.3265\n",
      "Epoch 4, Train Loss: 7.0093\n",
      "Epoch 4, Train Loss: 6.8632\n",
      "Epoch 4, Train Loss: 7.6473\n",
      "Epoch 4, Train Loss: 6.3848\n",
      "Epoch 4, Train Loss: 4.6898\n",
      "Epoch 4, Train Loss: 6.1106\n",
      "Epoch 4, Train Loss: 5.4233\n",
      "Epoch 4, Train Loss: 6.2954\n",
      "Epoch 4, Train Loss: 7.6006\n",
      "Epoch 4, Train Loss: 9.3891\n",
      "Epoch 4, Train Loss: 6.7329\n",
      "Epoch 4, Train Loss: 7.1234\n",
      "Epoch 4, Train Loss: 6.1672\n",
      "Epoch 4, Train Loss: 6.8692\n",
      "Epoch 4, Train Loss: 6.3889\n",
      "Epoch 4, Train Loss: 8.3400\n",
      "Epoch 4, Train Loss: 6.0054\n",
      "Epoch 4, Train Loss: 7.9965\n",
      "Epoch 4, Train Loss: 8.5060\n",
      "Epoch 4, Train Loss: 6.7234\n",
      "Epoch 4, Train Loss: 7.8321\n",
      "Epoch 4, Train Loss: 5.8221\n",
      "Epoch 4, Train Loss: 7.5964\n",
      "Epoch 4, Train Loss: 5.5286\n",
      "Epoch 4, Train Loss: 8.0641\n",
      "Epoch 4, Train Loss: 7.9353\n",
      "Epoch 4, Train Loss: 7.5592\n",
      "Epoch 4, Train Loss: 5.4422\n",
      "Epoch 4, Train Loss: 6.3781\n",
      "Epoch 4, Train Loss: 5.7514\n",
      "Epoch 4, Train Loss: 5.9137\n",
      "Epoch 4, Train Loss: 6.4647\n",
      "Epoch 4, Train Loss: 6.3921\n",
      "Epoch 4, Train Loss: 6.0509\n",
      "Epoch 4, Train Loss: 7.3336\n",
      "Epoch 4, Train Loss: 6.8392\n",
      "Epoch 4, Train Loss: 7.0068\n",
      "Epoch 4, Train Loss: 6.3473\n",
      "Epoch 4, Train Loss: 6.6200\n",
      "Epoch 4, Train Loss: 4.8428\n",
      "Epoch 4, Train Loss: 7.3289\n",
      "Epoch 4, Train Loss: 7.8315\n",
      "Epoch 4, Train Loss: 7.6116\n",
      "Epoch 4, Train Loss: 6.6800\n",
      "Epoch 4, Train Loss: 5.8990\n",
      "Epoch 4, Train Loss: 6.4462\n",
      "Epoch 4, Train Loss: 8.5643\n",
      "Epoch 4, Train Loss: 6.6607\n",
      "Epoch 4, Train Loss: 5.7842\n",
      "Epoch 4, Train Loss: 7.5085\n",
      "Epoch 4, Train Loss: 4.7777\n",
      "Epoch 4, Train Loss: 6.1985\n",
      "Epoch 4, Train Loss: 6.4902\n",
      "Epoch 4, Train Loss: 7.1252\n",
      "Epoch 4, Train Loss: 6.1684\n",
      "Epoch 4, Train Loss: 6.6208\n",
      "Epoch 4, Train Loss: 7.4124\n",
      "Epoch 4, Train Loss: 6.1844\n",
      "Epoch 4, Train Loss: 5.7897\n",
      "Epoch 4, Train Loss: 5.9082\n",
      "Epoch 4, Train Loss: 7.4024\n",
      "Epoch 4, Train Loss: 6.8315\n",
      "Epoch 4, Train Loss: 6.6853\n",
      "Epoch 4, Train Loss: 6.0079\n",
      "Epoch 4, Train Loss: 7.0388\n",
      "Epoch 4, Train Loss: 6.0056\n",
      "Epoch 4, Train Loss: 6.9901\n",
      "Epoch 4, Train Loss: 6.3806\n",
      "Epoch 4, Train Loss: 9.4926\n",
      "Epoch 4, Train Loss: 6.6392\n",
      "Epoch 4, Train Loss: 6.2225\n",
      "Epoch 4, Train Loss: 7.1764\n",
      "Epoch 4, Train Loss: 6.6634\n",
      "Epoch 4, Train Loss: 6.4766\n",
      "Epoch 4, Train Loss: 8.6537\n",
      "Epoch 4, Train Loss: 6.5955\n",
      "Epoch 4, Train Loss: 8.4641\n",
      "Epoch 4, Train Loss: 7.7831\n",
      "Epoch 4, Train Loss: 5.6616\n",
      "Epoch 4, Train Loss: 9.8111\n",
      "Epoch 4, Train Loss: 7.8507\n",
      "Epoch 4, Train Loss: 7.0089\n",
      "Epoch 4, Train Loss: 7.2592\n",
      "Epoch 4, Train Loss: 5.6034\n",
      "Epoch 4, Train Loss: 6.3328\n",
      "Epoch 4, Train Loss: 6.4367\n",
      "Epoch 4, Train Loss: 8.9688\n",
      "Epoch 4, Train Loss: 7.9614\n",
      "Epoch 4, Train Loss: 8.1903\n",
      "Epoch 4, Train Loss: 7.0063\n",
      "Epoch 4, Train Loss: 6.7027\n",
      "Epoch 4, Train Loss: 7.6191\n",
      "Epoch 4, Train Loss: 8.0976\n",
      "Epoch 4, Train Loss: 6.3838\n",
      "Epoch 4, Train Loss: 8.8993\n",
      "Epoch 4, Train Loss: 5.7925\n",
      "Epoch 4, Train Loss: 6.6437\n",
      "Epoch 4, Train Loss: 7.9248\n",
      "Epoch 4, Train Loss: 6.9113\n",
      "Epoch 4, Train Loss: 7.3283\n",
      "Epoch 4, Train Loss: 7.3749\n",
      "Epoch 4, Train Loss: 6.6414\n",
      "Epoch 4, Train Loss: 6.6588\n",
      "Epoch 4, Train Loss: 7.2837\n",
      "Epoch 4, Train Loss: 6.0319\n",
      "Epoch 4, Train Loss: 5.1676\n",
      "Epoch 4, Train Loss: 4.8372\n",
      "Epoch 4, Train Loss: 9.0340\n",
      "Epoch 4, Train Loss: 6.4874\n",
      "Epoch 4, Train Loss: 6.1975\n",
      "Epoch 4, Train Loss: 5.8653\n",
      "Epoch 4, Train Loss: 7.8891\n",
      "Epoch 4, Train Loss: 6.3033\n",
      "Epoch 4, Train Loss: 7.2898\n",
      "Epoch 4, Train Loss: 7.7048\n",
      "Epoch 4, Train Loss: 7.9605\n",
      "Epoch 4, Train Loss: 7.0230\n",
      "Epoch 4, Train Loss: 7.0730\n",
      "Epoch 4, Train Loss: 8.2287\n",
      "Epoch 4, Train Loss: 9.7350\n",
      "Epoch 4, Train Loss: 7.1129\n",
      "Epoch 4, Train Loss: 6.9863\n",
      "Epoch 4, Train Loss: 7.7218\n",
      "Epoch 4, Train Loss: 5.7216\n",
      "Epoch 4, Train Loss: 7.8840\n",
      "Epoch 4, Train Loss: 8.0588\n",
      "Epoch 4, Train Loss: 8.0095\n",
      "Epoch 4, Train Loss: 6.4710\n",
      "Epoch 4, Train Loss: 6.8399\n",
      "Epoch 4, Train Loss: 8.8408\n",
      "Epoch 4, Train Loss: 7.6403\n",
      "Epoch 4, Train Loss: 7.8967\n",
      "Epoch 4, Train Loss: 9.0712\n",
      "Epoch 4, Train Loss: 6.5865\n",
      "Epoch 4, Train Loss: 7.4743\n",
      "Epoch 4, Train Loss: 7.3641\n",
      "Epoch 4, Train Loss: 9.1485\n",
      "Epoch 4, Train Loss: 7.4061\n",
      "Epoch 4, Train Loss: 6.8545\n",
      "Epoch 4, Train Loss: 7.5254\n",
      "Epoch 4, Train Loss: 6.2278\n",
      "Epoch 4, Train Loss: 6.0850\n",
      "Epoch 4, Train Loss: 9.7650\n",
      "Epoch 4, Train Loss: 7.9230\n",
      "Epoch 4, Train Loss: 7.5684\n",
      "Epoch 4, Train Loss: 6.7736\n",
      "Epoch 4, Train Loss: 7.5118\n",
      "Epoch 4, Train Loss: 7.2729\n",
      "Epoch 4, Train Loss: 8.2309\n",
      "Epoch 4, Train Loss: 8.9057\n",
      "Epoch 4, Train Loss: 7.3234\n",
      "Epoch 4, Train Loss: 8.5971\n",
      "Epoch 4, Train Loss: 9.0115\n",
      "Epoch 4, Train Loss: 7.8087\n",
      "Epoch 4, Train Loss: 6.3316\n",
      "Epoch 4, Train Loss: 7.9709\n",
      "Epoch 4, Train Loss: 8.3561\n",
      "Epoch 4, Train Loss: 7.9739\n",
      "Epoch 4, Train Loss: 7.3284\n",
      "Epoch 4, Train Loss: 7.4914\n",
      "Epoch 4, Train Loss: 7.3418\n",
      "Epoch 4, Train Loss: 8.4994\n",
      "Epoch 4, Train Loss: 7.6108\n",
      "Epoch 4, Train Loss: 7.9754\n",
      "Epoch 4, Train Loss: 8.1099\n",
      "Epoch 4, Train Loss: 6.1575\n",
      "Epoch 4, Train Loss: 9.0890\n",
      "Epoch 4, Train Loss: 6.8371\n",
      "Epoch 4, Train Loss: 7.9096\n",
      "Epoch 4, Train Loss: 7.9630\n",
      "Epoch 4, Train Loss: 7.3000\n",
      "Epoch 4, Train Loss: 7.4781\n",
      "Epoch 4, Train Loss: 7.5094\n",
      "Epoch 4, Train Loss: 7.2913\n",
      "Epoch 4, Train Loss: 7.2213\n",
      "Epoch 4, Train Loss: 9.1494\n",
      "Epoch 4, Train Loss: 6.2210\n",
      "Epoch 4, Train Loss: 8.3354\n",
      "Epoch 4, Train Loss: 7.7729\n",
      "Epoch 4, Train Loss: 8.4502\n",
      "Epoch 4, Train Loss: 6.9784\n",
      "Epoch 4, Train Loss: 6.8300\n",
      "Epoch 4, Train Loss: 5.1835\n",
      "Epoch 4, Train Loss: 6.8167\n",
      "Epoch 4, Train Loss: 6.6694\n",
      "Epoch 4, Train Loss: 7.4186\n",
      "Epoch 4, Train Loss: 8.0299\n",
      "Epoch 4, Train Loss: 8.5287\n",
      "Epoch 4, Train Loss: 7.4172\n",
      "Epoch 4, Train Loss: 8.2580\n",
      "Epoch 4, Train Loss: 8.4141\n",
      "Epoch 4, Train Loss: 6.6113\n",
      "Epoch 4, Train Loss: 7.6902\n",
      "Epoch 4, Train Loss: 7.0629\n",
      "Epoch 4, Train Loss: 6.8475\n",
      "Epoch 4, Train Loss: 9.0341\n",
      "Epoch 4, Train Loss: 7.4106\n",
      "Epoch 4, Train Loss: 8.8092\n",
      "Epoch 4, Train Loss: 7.3755\n",
      "Epoch 4, Train Loss: 7.8451\n",
      "Epoch 4, Train Loss: 7.7652\n",
      "Epoch 4, Train Loss: 7.6448\n",
      "Epoch 4, Train Loss: 6.5233\n",
      "Epoch 4, Train Loss: 7.7533\n",
      "Epoch 4, Train Loss: 5.9921\n",
      "Epoch 4, Train Loss: 6.9002\n",
      "Epoch 4, Train Loss: 8.7652\n",
      "Epoch 4, Train Loss: 6.7545\n",
      "Epoch 4, Train Loss: 7.7963\n",
      "Epoch 4, Train Loss: 8.1826\n",
      "Epoch 4, Train Loss: 8.1462\n",
      "Epoch 4, Train Loss: 7.6769\n",
      "Epoch 4, Train Loss: 7.7535\n",
      "Epoch 4, Train Loss: 8.9504\n",
      "Epoch 4, Train Loss: 8.5815\n",
      "Epoch 4, Train Loss: 7.9740\n",
      "Epoch 4, Train Loss: 6.6017\n",
      "Epoch 4, Train Loss: 7.1831\n",
      "Epoch 4, Train Loss: 6.4201\n",
      "Epoch 4, Train Loss: 8.4935\n",
      "Epoch 4, Train Loss: 9.2090\n",
      "Epoch 4, Train Loss: 7.7455\n",
      "Epoch 4, Train Loss: 7.8078\n",
      "Epoch 4, Train Loss: 6.6362\n",
      "Epoch 4, Train Loss: 8.5275\n",
      "Epoch 4, Train Loss: 6.8896\n",
      "Epoch 4, Train Loss: 7.2515\n",
      "Epoch 4, Train Loss: 8.9779\n",
      "Epoch 4, Train Loss: 6.5418\n",
      "Epoch 4, Train Loss: 7.1989\n",
      "Epoch 4, Train Loss: 7.1497\n",
      "Epoch 4, Train Loss: 8.9351\n",
      "Epoch 4, Train Loss: 7.5427\n",
      "Epoch 4, Train Loss: 7.8755\n",
      "Epoch 4, Train Loss: 7.6157\n",
      "Epoch 4, Train Loss: 6.9604\n",
      "Epoch 4, Train Loss: 8.2033\n",
      "Epoch 4, Train Loss: 8.0360\n",
      "Epoch 4, Train Loss: 9.0506\n",
      "Epoch 4, Train Loss: 7.9600\n",
      "Epoch 4, Train Loss: 8.5115\n",
      "Epoch 4, Train Loss: 8.1798\n",
      "Epoch 4, Train Loss: 6.6368\n",
      "Epoch 4, Train Loss: 7.7207\n",
      "Epoch 4, Train Loss: 7.9584\n",
      "Epoch 4, Train Loss: 8.9370\n",
      "Epoch 4, Train Loss: 6.6055\n",
      "Epoch 4, Train Loss: 7.7312\n",
      "Epoch 4, Train Loss: 6.0787\n",
      "Epoch 4, Train Loss: 7.8723\n",
      "Epoch 4, Train Loss: 7.0763\n",
      "Epoch 4, Train Loss: 6.7367\n",
      "Epoch 4, Train Loss: 6.8788\n",
      "Epoch 4, Train Loss: 8.2245\n",
      "Epoch 4, Train Loss: 6.9038\n",
      "Epoch 4, Train Loss: 7.3853\n",
      "Epoch 4, Train Loss: 6.9857\n",
      "Epoch 4, Train Loss: 8.1420\n",
      "Epoch 4, Train Loss: 8.5356\n",
      "Epoch 4, Train Loss: 7.4264\n",
      "Epoch 4, Train Loss: 8.0129\n",
      "Epoch 4, Avg Loss: 6.9864, Acc: 37.33%\n",
      "Epoch 5, Avg Loss: 8.2988, Acc: 37.57%\n",
      "Epoch 6, Train Loss: 9.3233\n",
      "Epoch 6, Train Loss: 8.9443\n",
      "Epoch 6, Train Loss: 9.2434\n",
      "Epoch 6, Train Loss: 8.3006\n",
      "Epoch 6, Train Loss: 7.6673\n",
      "Epoch 6, Train Loss: 11.8350\n",
      "Epoch 6, Train Loss: 7.7689\n",
      "Epoch 6, Train Loss: 10.1247\n",
      "Epoch 6, Train Loss: 8.8067\n",
      "Epoch 6, Train Loss: 7.7180\n",
      "Epoch 6, Train Loss: 8.9765\n",
      "Epoch 6, Train Loss: 9.4485\n",
      "Epoch 6, Train Loss: 9.5624\n",
      "Epoch 6, Train Loss: 10.2397\n",
      "Epoch 6, Train Loss: 7.9071\n",
      "Epoch 6, Train Loss: 8.9486\n",
      "Epoch 6, Train Loss: 9.3214\n",
      "Epoch 6, Train Loss: 9.3328\n",
      "Epoch 6, Train Loss: 8.2346\n",
      "Epoch 6, Train Loss: 7.4166\n",
      "Epoch 6, Train Loss: 10.4971\n",
      "Epoch 6, Train Loss: 8.6230\n",
      "Epoch 6, Train Loss: 10.1088\n",
      "Epoch 6, Train Loss: 9.2964\n",
      "Epoch 6, Train Loss: 9.4563\n",
      "Epoch 6, Train Loss: 7.3879\n",
      "Epoch 6, Train Loss: 6.6764\n",
      "Epoch 6, Train Loss: 7.9213\n",
      "Epoch 6, Train Loss: 8.5639\n",
      "Epoch 6, Train Loss: 9.1267\n",
      "Epoch 6, Train Loss: 8.9767\n",
      "Epoch 6, Train Loss: 7.7361\n",
      "Epoch 6, Train Loss: 7.2071\n",
      "Epoch 6, Train Loss: 8.2242\n",
      "Epoch 6, Train Loss: 8.1193\n",
      "Epoch 6, Train Loss: 8.2765\n",
      "Epoch 6, Train Loss: 9.1917\n",
      "Epoch 6, Train Loss: 9.5565\n",
      "Epoch 6, Train Loss: 8.7846\n",
      "Epoch 6, Train Loss: 7.7062\n",
      "Epoch 6, Train Loss: 6.8621\n",
      "Epoch 6, Train Loss: 8.2162\n",
      "Epoch 6, Train Loss: 8.9193\n",
      "Epoch 6, Train Loss: 7.4402\n",
      "Epoch 6, Train Loss: 7.1306\n",
      "Epoch 6, Train Loss: 10.2092\n",
      "Epoch 6, Train Loss: 9.6200\n",
      "Epoch 6, Train Loss: 9.1223\n",
      "Epoch 6, Train Loss: 9.1103\n",
      "Epoch 6, Train Loss: 9.8922\n",
      "Epoch 6, Train Loss: 11.2916\n",
      "Epoch 6, Train Loss: 8.6142\n",
      "Epoch 6, Train Loss: 8.3440\n",
      "Epoch 6, Train Loss: 9.5073\n",
      "Epoch 6, Train Loss: 9.9809\n",
      "Epoch 6, Train Loss: 7.2885\n",
      "Epoch 6, Train Loss: 9.4861\n",
      "Epoch 6, Train Loss: 9.3996\n",
      "Epoch 6, Train Loss: 10.5943\n",
      "Epoch 6, Train Loss: 9.6385\n",
      "Epoch 6, Train Loss: 8.7305\n",
      "Epoch 6, Train Loss: 8.0800\n",
      "Epoch 6, Train Loss: 10.5390\n",
      "Epoch 6, Train Loss: 8.8004\n",
      "Epoch 6, Train Loss: 9.4633\n",
      "Epoch 6, Train Loss: 10.1484\n",
      "Epoch 6, Train Loss: 10.1820\n",
      "Epoch 6, Train Loss: 9.2731\n",
      "Epoch 6, Train Loss: 7.9729\n",
      "Epoch 6, Train Loss: 8.4380\n",
      "Epoch 6, Train Loss: 8.2358\n",
      "Epoch 6, Train Loss: 10.4904\n",
      "Epoch 6, Train Loss: 9.2215\n",
      "Epoch 6, Train Loss: 8.9807\n",
      "Epoch 6, Train Loss: 11.0347\n",
      "Epoch 6, Train Loss: 8.0229\n",
      "Epoch 6, Train Loss: 6.8114\n",
      "Epoch 6, Train Loss: 9.8062\n",
      "Epoch 6, Train Loss: 7.9059\n",
      "Epoch 6, Train Loss: 8.5912\n",
      "Epoch 6, Train Loss: 8.8633\n",
      "Epoch 6, Train Loss: 9.5848\n",
      "Epoch 6, Train Loss: 9.3433\n",
      "Epoch 6, Train Loss: 8.1197\n",
      "Epoch 6, Train Loss: 11.1985\n",
      "Epoch 6, Train Loss: 10.6306\n",
      "Epoch 6, Train Loss: 7.9263\n",
      "Epoch 6, Train Loss: 7.8647\n",
      "Epoch 6, Train Loss: 9.4858\n",
      "Epoch 6, Train Loss: 9.8217\n",
      "Epoch 6, Train Loss: 8.5843\n",
      "Epoch 6, Train Loss: 7.6838\n",
      "Epoch 6, Train Loss: 7.6656\n",
      "Epoch 6, Train Loss: 8.2128\n",
      "Epoch 6, Train Loss: 7.4724\n",
      "Epoch 6, Train Loss: 10.4833\n",
      "Epoch 6, Train Loss: 8.5011\n",
      "Epoch 6, Train Loss: 10.0657\n",
      "Epoch 6, Train Loss: 9.7286\n",
      "Epoch 6, Train Loss: 8.4665\n",
      "Epoch 6, Train Loss: 9.4754\n",
      "Epoch 6, Train Loss: 8.5440\n",
      "Epoch 6, Train Loss: 7.3507\n",
      "Epoch 6, Train Loss: 9.1132\n",
      "Epoch 6, Train Loss: 9.2504\n",
      "Epoch 6, Train Loss: 7.9517\n",
      "Epoch 6, Train Loss: 7.8601\n",
      "Epoch 6, Train Loss: 9.0169\n",
      "Epoch 6, Train Loss: 9.3158\n",
      "Epoch 6, Train Loss: 11.0381\n",
      "Epoch 6, Train Loss: 9.0742\n",
      "Epoch 6, Train Loss: 10.4928\n",
      "Epoch 6, Train Loss: 8.9873\n",
      "Epoch 6, Train Loss: 9.9343\n",
      "Epoch 6, Train Loss: 7.5404\n",
      "Epoch 6, Train Loss: 7.5848\n",
      "Epoch 6, Train Loss: 9.7664\n",
      "Epoch 6, Train Loss: 9.5911\n",
      "Epoch 6, Train Loss: 9.6171\n",
      "Epoch 6, Train Loss: 9.5498\n",
      "Epoch 6, Train Loss: 10.6087\n",
      "Epoch 6, Train Loss: 9.1730\n",
      "Epoch 6, Train Loss: 10.5388\n",
      "Epoch 6, Train Loss: 6.4663\n",
      "Epoch 6, Train Loss: 10.2931\n",
      "Epoch 6, Train Loss: 9.3338\n",
      "Epoch 6, Train Loss: 10.7357\n",
      "Epoch 6, Train Loss: 8.5893\n",
      "Epoch 6, Train Loss: 6.8170\n",
      "Epoch 6, Train Loss: 9.8544\n",
      "Epoch 6, Train Loss: 7.6481\n",
      "Epoch 6, Train Loss: 9.5119\n",
      "Epoch 6, Train Loss: 11.6491\n",
      "Epoch 6, Train Loss: 10.3105\n",
      "Epoch 6, Train Loss: 11.0480\n",
      "Epoch 6, Train Loss: 8.0504\n",
      "Epoch 6, Train Loss: 9.9977\n",
      "Epoch 6, Train Loss: 7.8675\n",
      "Epoch 6, Train Loss: 9.0051\n",
      "Epoch 6, Train Loss: 8.1823\n",
      "Epoch 6, Train Loss: 10.7608\n",
      "Epoch 6, Train Loss: 9.6509\n",
      "Epoch 6, Train Loss: 9.3775\n",
      "Epoch 6, Train Loss: 8.7057\n",
      "Epoch 6, Train Loss: 7.7069\n",
      "Epoch 6, Train Loss: 9.4065\n",
      "Epoch 6, Train Loss: 8.2067\n",
      "Epoch 6, Train Loss: 9.1761\n",
      "Epoch 6, Train Loss: 10.8469\n",
      "Epoch 6, Train Loss: 8.7719\n",
      "Epoch 6, Train Loss: 9.6530\n",
      "Epoch 6, Train Loss: 8.6781\n",
      "Epoch 6, Train Loss: 9.7848\n",
      "Epoch 6, Train Loss: 10.6594\n",
      "Epoch 6, Train Loss: 9.9394\n",
      "Epoch 6, Train Loss: 9.6257\n",
      "Epoch 6, Train Loss: 10.3549\n",
      "Epoch 6, Train Loss: 10.3161\n",
      "Epoch 6, Train Loss: 11.4236\n",
      "Epoch 6, Train Loss: 7.2163\n",
      "Epoch 6, Train Loss: 10.5764\n",
      "Epoch 6, Train Loss: 8.2275\n",
      "Epoch 6, Train Loss: 8.6710\n",
      "Epoch 6, Train Loss: 7.9772\n",
      "Epoch 6, Train Loss: 8.2832\n",
      "Epoch 6, Train Loss: 9.3313\n",
      "Epoch 6, Train Loss: 9.3245\n",
      "Epoch 6, Train Loss: 9.6236\n",
      "Epoch 6, Train Loss: 9.8820\n",
      "Epoch 6, Train Loss: 8.2911\n",
      "Epoch 6, Train Loss: 8.7709\n",
      "Epoch 6, Train Loss: 8.0627\n",
      "Epoch 6, Train Loss: 7.5127\n",
      "Epoch 6, Train Loss: 9.1438\n",
      "Epoch 6, Train Loss: 10.1310\n",
      "Epoch 6, Train Loss: 9.1183\n",
      "Epoch 6, Train Loss: 9.6499\n",
      "Epoch 6, Train Loss: 9.7878\n",
      "Epoch 6, Train Loss: 9.8433\n",
      "Epoch 6, Train Loss: 8.6206\n",
      "Epoch 6, Train Loss: 11.1026\n",
      "Epoch 6, Train Loss: 8.5886\n",
      "Epoch 6, Train Loss: 7.5421\n",
      "Epoch 6, Train Loss: 11.0969\n",
      "Epoch 6, Train Loss: 9.1711\n",
      "Epoch 6, Train Loss: 8.9612\n",
      "Epoch 6, Train Loss: 9.5582\n",
      "Epoch 6, Train Loss: 8.5063\n",
      "Epoch 6, Train Loss: 9.8219\n",
      "Epoch 6, Train Loss: 10.4519\n",
      "Epoch 6, Train Loss: 11.0249\n",
      "Epoch 6, Train Loss: 10.8087\n",
      "Epoch 6, Train Loss: 10.0261\n",
      "Epoch 6, Train Loss: 8.5135\n",
      "Epoch 6, Train Loss: 8.4813\n",
      "Epoch 6, Train Loss: 7.5933\n",
      "Epoch 6, Train Loss: 8.3793\n",
      "Epoch 6, Train Loss: 7.1795\n",
      "Epoch 6, Train Loss: 9.4471\n",
      "Epoch 6, Train Loss: 10.6469\n",
      "Epoch 6, Train Loss: 9.7390\n",
      "Epoch 6, Train Loss: 9.4126\n",
      "Epoch 6, Train Loss: 9.4322\n",
      "Epoch 6, Train Loss: 10.1478\n",
      "Epoch 6, Train Loss: 9.6653\n",
      "Epoch 6, Train Loss: 8.3842\n",
      "Epoch 6, Train Loss: 10.2676\n",
      "Epoch 6, Train Loss: 10.1370\n",
      "Epoch 6, Train Loss: 10.0697\n",
      "Epoch 6, Train Loss: 8.3849\n",
      "Epoch 6, Train Loss: 11.7095\n",
      "Epoch 6, Train Loss: 11.3047\n",
      "Epoch 6, Train Loss: 8.6880\n",
      "Epoch 6, Train Loss: 7.0664\n",
      "Epoch 6, Train Loss: 8.3178\n",
      "Epoch 6, Train Loss: 9.5237\n",
      "Epoch 6, Train Loss: 10.5868\n",
      "Epoch 6, Train Loss: 9.0928\n",
      "Epoch 6, Train Loss: 10.1280\n",
      "Epoch 6, Train Loss: 8.8248\n",
      "Epoch 6, Train Loss: 8.6140\n",
      "Epoch 6, Train Loss: 8.6862\n",
      "Epoch 6, Train Loss: 10.7951\n",
      "Epoch 6, Train Loss: 9.6154\n",
      "Epoch 6, Train Loss: 9.2270\n",
      "Epoch 6, Train Loss: 7.8588\n",
      "Epoch 6, Train Loss: 9.9972\n",
      "Epoch 6, Train Loss: 11.2532\n",
      "Epoch 6, Train Loss: 9.2374\n",
      "Epoch 6, Train Loss: 9.9267\n",
      "Epoch 6, Train Loss: 9.2141\n",
      "Epoch 6, Train Loss: 9.4609\n",
      "Epoch 6, Train Loss: 9.5827\n",
      "Epoch 6, Train Loss: 7.2219\n",
      "Epoch 6, Train Loss: 7.7941\n",
      "Epoch 6, Train Loss: 8.9844\n",
      "Epoch 6, Train Loss: 9.9216\n",
      "Epoch 6, Train Loss: 10.0531\n",
      "Epoch 6, Train Loss: 7.6019\n",
      "Epoch 6, Train Loss: 11.7396\n",
      "Epoch 6, Train Loss: 8.8483\n",
      "Epoch 6, Train Loss: 10.5793\n",
      "Epoch 6, Train Loss: 10.2807\n",
      "Epoch 6, Train Loss: 7.4484\n",
      "Epoch 6, Train Loss: 11.1083\n",
      "Epoch 6, Train Loss: 8.4360\n",
      "Epoch 6, Train Loss: 10.7652\n",
      "Epoch 6, Train Loss: 8.7934\n",
      "Epoch 6, Train Loss: 9.4965\n",
      "Epoch 6, Train Loss: 7.9763\n",
      "Epoch 6, Train Loss: 9.4295\n",
      "Epoch 6, Train Loss: 10.3617\n",
      "Epoch 6, Train Loss: 10.7993\n",
      "Epoch 6, Train Loss: 7.2707\n",
      "Epoch 6, Train Loss: 8.3480\n",
      "Epoch 6, Train Loss: 8.2413\n",
      "Epoch 6, Train Loss: 8.2520\n",
      "Epoch 6, Train Loss: 10.4585\n",
      "Epoch 6, Train Loss: 11.2580\n",
      "Epoch 6, Train Loss: 7.8044\n",
      "Epoch 6, Train Loss: 8.7644\n",
      "Epoch 6, Train Loss: 9.5343\n",
      "Epoch 6, Train Loss: 9.8354\n",
      "Epoch 6, Train Loss: 8.8466\n",
      "Epoch 6, Train Loss: 7.9878\n",
      "Epoch 6, Train Loss: 9.7770\n",
      "Epoch 6, Train Loss: 10.9958\n",
      "Epoch 6, Train Loss: 8.1556\n",
      "Epoch 6, Train Loss: 9.6748\n",
      "Epoch 6, Train Loss: 7.4940\n",
      "Epoch 6, Train Loss: 10.4163\n",
      "Epoch 6, Train Loss: 11.8800\n",
      "Epoch 6, Train Loss: 7.9060\n",
      "Epoch 6, Train Loss: 10.8939\n",
      "Epoch 6, Train Loss: 10.9950\n",
      "Epoch 6, Train Loss: 8.2560\n",
      "Epoch 6, Train Loss: 7.5338\n",
      "Epoch 6, Train Loss: 9.8105\n",
      "Epoch 6, Train Loss: 8.7409\n",
      "Epoch 6, Train Loss: 8.6435\n",
      "Epoch 6, Train Loss: 10.0800\n",
      "Epoch 6, Train Loss: 9.4301\n",
      "Epoch 6, Train Loss: 8.4798\n",
      "Epoch 6, Train Loss: 8.4630\n",
      "Epoch 6, Train Loss: 8.8446\n",
      "Epoch 6, Train Loss: 9.6748\n",
      "Epoch 6, Train Loss: 11.1042\n",
      "Epoch 6, Train Loss: 8.5560\n",
      "Epoch 6, Train Loss: 10.1343\n",
      "Epoch 6, Train Loss: 8.5525\n",
      "Epoch 6, Train Loss: 10.8076\n",
      "Epoch 6, Train Loss: 9.2589\n",
      "Epoch 6, Train Loss: 9.4291\n",
      "Epoch 6, Train Loss: 8.9485\n",
      "Epoch 6, Train Loss: 9.7397\n",
      "Epoch 6, Train Loss: 7.2796\n",
      "Epoch 6, Train Loss: 9.7380\n",
      "Epoch 6, Train Loss: 10.2925\n",
      "Epoch 6, Train Loss: 9.4407\n",
      "Epoch 6, Train Loss: 9.1546\n",
      "Epoch 6, Train Loss: 10.5531\n",
      "Epoch 6, Train Loss: 8.9570\n",
      "Epoch 6, Train Loss: 11.4298\n",
      "Epoch 6, Train Loss: 8.3326\n",
      "Epoch 6, Train Loss: 9.2884\n",
      "Epoch 6, Train Loss: 7.0931\n",
      "Epoch 6, Train Loss: 9.2791\n",
      "Epoch 6, Train Loss: 7.3317\n",
      "Epoch 6, Train Loss: 9.2945\n",
      "Epoch 6, Train Loss: 8.7420\n",
      "Epoch 6, Train Loss: 9.8845\n",
      "Epoch 6, Train Loss: 9.1550\n",
      "Epoch 6, Train Loss: 10.2355\n",
      "Epoch 6, Train Loss: 7.5430\n",
      "Epoch 6, Train Loss: 11.2636\n",
      "Epoch 6, Train Loss: 10.0694\n",
      "Epoch 6, Train Loss: 8.7804\n",
      "Epoch 6, Train Loss: 8.2261\n",
      "Epoch 6, Train Loss: 7.3135\n",
      "Epoch 6, Train Loss: 9.5344\n",
      "Epoch 6, Train Loss: 8.4039\n",
      "Epoch 6, Train Loss: 8.3958\n",
      "Epoch 6, Train Loss: 8.2517\n",
      "Epoch 6, Train Loss: 10.8847\n",
      "Epoch 6, Train Loss: 9.8943\n",
      "Epoch 6, Train Loss: 8.8423\n",
      "Epoch 6, Train Loss: 9.2588\n",
      "Epoch 6, Train Loss: 8.3788\n",
      "Epoch 6, Train Loss: 9.2358\n",
      "Epoch 6, Train Loss: 9.2806\n",
      "Epoch 6, Train Loss: 10.0262\n",
      "Epoch 6, Train Loss: 9.4005\n",
      "Epoch 6, Train Loss: 10.3769\n",
      "Epoch 6, Train Loss: 9.9023\n",
      "Epoch 6, Train Loss: 9.7805\n",
      "Epoch 6, Train Loss: 10.7707\n",
      "Epoch 6, Train Loss: 11.0910\n",
      "Epoch 6, Train Loss: 8.6841\n",
      "Epoch 6, Train Loss: 9.2142\n",
      "Epoch 6, Train Loss: 9.2269\n",
      "Epoch 6, Train Loss: 8.6566\n",
      "Epoch 6, Train Loss: 11.7824\n",
      "Epoch 6, Train Loss: 9.5728\n",
      "Epoch 6, Train Loss: 10.3679\n",
      "Epoch 6, Train Loss: 10.6486\n",
      "Epoch 6, Train Loss: 8.2427\n",
      "Epoch 6, Train Loss: 9.8136\n",
      "Epoch 6, Train Loss: 11.0974\n",
      "Epoch 6, Train Loss: 10.4080\n",
      "Epoch 6, Train Loss: 9.7807\n",
      "Epoch 6, Train Loss: 9.6524\n",
      "Epoch 6, Train Loss: 9.3375\n",
      "Epoch 6, Train Loss: 12.5449\n",
      "Epoch 6, Train Loss: 10.0675\n",
      "Epoch 6, Train Loss: 11.1680\n",
      "Epoch 6, Train Loss: 8.8107\n",
      "Epoch 6, Train Loss: 7.8446\n",
      "Epoch 6, Train Loss: 7.9672\n",
      "Epoch 6, Train Loss: 9.8039\n",
      "Epoch 6, Train Loss: 10.4691\n",
      "Epoch 6, Train Loss: 9.3049\n",
      "Epoch 6, Train Loss: 10.5585\n",
      "Epoch 6, Train Loss: 11.2355\n",
      "Epoch 6, Train Loss: 10.5505\n",
      "Epoch 6, Train Loss: 8.6502\n",
      "Epoch 6, Train Loss: 11.3803\n",
      "Epoch 6, Train Loss: 10.2658\n",
      "Epoch 6, Train Loss: 8.1486\n",
      "Epoch 6, Train Loss: 8.9801\n",
      "Epoch 6, Train Loss: 9.6335\n",
      "Epoch 6, Train Loss: 8.5051\n",
      "Epoch 6, Train Loss: 7.8320\n",
      "Epoch 6, Train Loss: 8.9435\n",
      "Epoch 6, Train Loss: 10.3973\n",
      "Epoch 6, Train Loss: 10.5462\n",
      "Epoch 6, Train Loss: 11.1157\n",
      "Epoch 6, Train Loss: 12.1641\n",
      "Epoch 6, Train Loss: 8.7473\n",
      "Epoch 6, Train Loss: 10.3445\n",
      "Epoch 6, Train Loss: 9.6870\n",
      "Epoch 6, Train Loss: 10.5222\n",
      "Epoch 6, Train Loss: 9.1661\n",
      "Epoch 6, Train Loss: 10.0182\n",
      "Epoch 6, Train Loss: 9.3283\n",
      "Epoch 6, Train Loss: 9.7706\n",
      "Epoch 6, Train Loss: 7.9420\n",
      "Epoch 6, Train Loss: 10.3272\n",
      "Epoch 6, Train Loss: 10.8078\n",
      "Epoch 6, Train Loss: 9.5439\n",
      "Epoch 6, Train Loss: 10.9075\n",
      "Epoch 6, Train Loss: 10.1407\n",
      "Epoch 6, Train Loss: 11.3471\n",
      "Epoch 6, Train Loss: 10.2942\n",
      "Epoch 6, Train Loss: 11.3470\n",
      "Epoch 6, Train Loss: 10.6655\n",
      "Epoch 6, Train Loss: 11.7661\n",
      "Epoch 6, Train Loss: 7.8912\n",
      "Epoch 6, Train Loss: 9.4085\n",
      "Epoch 6, Train Loss: 9.7011\n",
      "Epoch 6, Train Loss: 9.4836\n",
      "Epoch 6, Train Loss: 9.7247\n",
      "Epoch 6, Train Loss: 9.6407\n",
      "Epoch 6, Train Loss: 9.4819\n",
      "Epoch 6, Train Loss: 11.1676\n",
      "Epoch 6, Train Loss: 8.6450\n",
      "Epoch 6, Train Loss: 10.0841\n",
      "Epoch 6, Train Loss: 10.8115\n",
      "Epoch 6, Train Loss: 7.0575\n",
      "Epoch 6, Train Loss: 9.4904\n",
      "Epoch 6, Train Loss: 10.0637\n",
      "Epoch 6, Train Loss: 9.4139\n",
      "Epoch 6, Train Loss: 7.7587\n",
      "Epoch 6, Train Loss: 10.9235\n",
      "Epoch 6, Train Loss: 9.3444\n",
      "Epoch 6, Train Loss: 11.7551\n",
      "Epoch 6, Train Loss: 11.8011\n",
      "Epoch 6, Train Loss: 9.3540\n",
      "Epoch 6, Train Loss: 9.3469\n",
      "Epoch 6, Train Loss: 8.2046\n",
      "Epoch 6, Train Loss: 9.8115\n",
      "Epoch 6, Train Loss: 10.2575\n",
      "Epoch 6, Train Loss: 10.2793\n",
      "Epoch 6, Train Loss: 11.1072\n",
      "Epoch 6, Train Loss: 8.8123\n",
      "Epoch 6, Train Loss: 7.5283\n",
      "Epoch 6, Train Loss: 9.6384\n",
      "Epoch 6, Train Loss: 7.8129\n",
      "Epoch 6, Train Loss: 9.1087\n",
      "Epoch 6, Train Loss: 9.5755\n",
      "Epoch 6, Train Loss: 10.3235\n",
      "Epoch 6, Train Loss: 9.8113\n",
      "Epoch 6, Train Loss: 9.5650\n",
      "Epoch 6, Train Loss: 11.5211\n",
      "Epoch 6, Train Loss: 9.9260\n",
      "Epoch 6, Train Loss: 10.4278\n",
      "Epoch 6, Train Loss: 10.1552\n",
      "Epoch 6, Train Loss: 9.0497\n",
      "Epoch 6, Train Loss: 9.5781\n",
      "Epoch 6, Train Loss: 7.7685\n",
      "Epoch 6, Train Loss: 9.5551\n",
      "Epoch 6, Train Loss: 11.5636\n",
      "Epoch 6, Train Loss: 10.6228\n",
      "Epoch 6, Train Loss: 9.2137\n",
      "Epoch 6, Train Loss: 10.0365\n",
      "Epoch 6, Train Loss: 8.7817\n",
      "Epoch 6, Train Loss: 7.5241\n",
      "Epoch 6, Train Loss: 8.8718\n",
      "Epoch 6, Train Loss: 10.3297\n",
      "Epoch 6, Train Loss: 11.8828\n",
      "Epoch 6, Train Loss: 7.5771\n",
      "Epoch 6, Train Loss: 9.5960\n",
      "Epoch 6, Train Loss: 9.7739\n",
      "Epoch 6, Train Loss: 9.6166\n",
      "Epoch 6, Train Loss: 8.0049\n",
      "Epoch 6, Train Loss: 9.0691\n",
      "Epoch 6, Train Loss: 8.2203\n",
      "Epoch 6, Train Loss: 10.7142\n",
      "Epoch 6, Train Loss: 9.8040\n",
      "Epoch 6, Train Loss: 10.0560\n",
      "Epoch 6, Train Loss: 9.6179\n",
      "Epoch 6, Train Loss: 10.3411\n",
      "Epoch 6, Train Loss: 8.4024\n",
      "Epoch 6, Train Loss: 9.6506\n",
      "Epoch 6, Train Loss: 8.2673\n",
      "Epoch 6, Train Loss: 9.8189\n",
      "Epoch 6, Train Loss: 11.9515\n",
      "Epoch 6, Train Loss: 8.6350\n",
      "Epoch 6, Train Loss: 10.0554\n",
      "Epoch 6, Train Loss: 11.7796\n",
      "Epoch 6, Avg Loss: 9.3519, Acc: 37.56%\n",
      "Epoch 7, Avg Loss: 10.3550, Acc: 37.68%\n",
      "Epoch 8, Train Loss: 11.0353\n",
      "Epoch 8, Train Loss: 9.9961\n",
      "Epoch 8, Train Loss: 11.6886\n",
      "Epoch 8, Train Loss: 10.5395\n",
      "Epoch 8, Train Loss: 9.3972\n",
      "Epoch 8, Train Loss: 10.7968\n",
      "Epoch 8, Train Loss: 9.4768\n",
      "Epoch 8, Train Loss: 12.0381\n",
      "Epoch 8, Train Loss: 11.4262\n",
      "Epoch 8, Train Loss: 12.0895\n",
      "Epoch 8, Train Loss: 8.9061\n",
      "Epoch 8, Train Loss: 10.6570\n",
      "Epoch 8, Train Loss: 9.6582\n",
      "Epoch 8, Train Loss: 9.9536\n",
      "Epoch 8, Train Loss: 10.3456\n",
      "Epoch 8, Train Loss: 8.9769\n",
      "Epoch 8, Train Loss: 10.1778\n",
      "Epoch 8, Train Loss: 12.9431\n",
      "Epoch 8, Train Loss: 11.5599\n",
      "Epoch 8, Train Loss: 11.1274\n",
      "Epoch 8, Train Loss: 11.5821\n",
      "Epoch 8, Train Loss: 12.1239\n",
      "Epoch 8, Train Loss: 8.7928\n",
      "Epoch 8, Train Loss: 10.1923\n",
      "Epoch 8, Train Loss: 10.4819\n",
      "Epoch 8, Train Loss: 9.7258\n",
      "Epoch 8, Train Loss: 11.2752\n",
      "Epoch 8, Train Loss: 10.4560\n",
      "Epoch 8, Train Loss: 11.3122\n",
      "Epoch 8, Train Loss: 9.4167\n",
      "Epoch 8, Train Loss: 7.9757\n",
      "Epoch 8, Train Loss: 11.5745\n",
      "Epoch 8, Train Loss: 10.4057\n",
      "Epoch 8, Train Loss: 8.7130\n",
      "Epoch 8, Train Loss: 10.1529\n",
      "Epoch 8, Train Loss: 12.8609\n",
      "Epoch 8, Train Loss: 11.9237\n",
      "Epoch 8, Train Loss: 9.8077\n",
      "Epoch 8, Train Loss: 10.8309\n",
      "Epoch 8, Train Loss: 9.2843\n",
      "Epoch 8, Train Loss: 11.2230\n",
      "Epoch 8, Train Loss: 10.8964\n",
      "Epoch 8, Train Loss: 12.0320\n",
      "Epoch 8, Train Loss: 10.7652\n",
      "Epoch 8, Train Loss: 10.9978\n",
      "Epoch 8, Train Loss: 12.4218\n",
      "Epoch 8, Train Loss: 9.7878\n",
      "Epoch 8, Train Loss: 10.2571\n",
      "Epoch 8, Train Loss: 10.3323\n",
      "Epoch 8, Train Loss: 10.7301\n",
      "Epoch 8, Train Loss: 12.5801\n",
      "Epoch 8, Train Loss: 12.4209\n",
      "Epoch 8, Train Loss: 13.2519\n",
      "Epoch 8, Train Loss: 9.5751\n",
      "Epoch 8, Train Loss: 10.7768\n",
      "Epoch 8, Train Loss: 10.8747\n",
      "Epoch 8, Train Loss: 10.0600\n",
      "Epoch 8, Train Loss: 9.2347\n",
      "Epoch 8, Train Loss: 8.9427\n",
      "Epoch 8, Train Loss: 11.6153\n",
      "Epoch 8, Train Loss: 12.6306\n",
      "Epoch 8, Train Loss: 13.1582\n",
      "Epoch 8, Train Loss: 8.8744\n",
      "Epoch 8, Train Loss: 9.4737\n",
      "Epoch 8, Train Loss: 13.1620\n",
      "Epoch 8, Train Loss: 10.8450\n",
      "Epoch 8, Train Loss: 10.2891\n",
      "Epoch 8, Train Loss: 12.6329\n",
      "Epoch 8, Train Loss: 9.9084\n",
      "Epoch 8, Train Loss: 9.9487\n",
      "Epoch 8, Train Loss: 14.0644\n",
      "Epoch 8, Train Loss: 11.4094\n",
      "Epoch 8, Train Loss: 10.2291\n",
      "Epoch 8, Train Loss: 10.6146\n",
      "Epoch 8, Train Loss: 10.6055\n",
      "Epoch 8, Train Loss: 9.8470\n",
      "Epoch 8, Train Loss: 11.9365\n",
      "Epoch 8, Train Loss: 9.4758\n",
      "Epoch 8, Train Loss: 10.3907\n",
      "Epoch 8, Train Loss: 11.0185\n",
      "Epoch 8, Train Loss: 11.3898\n",
      "Epoch 8, Train Loss: 9.1135\n",
      "Epoch 8, Train Loss: 9.6670\n",
      "Epoch 8, Train Loss: 9.1831\n",
      "Epoch 8, Train Loss: 10.4579\n",
      "Epoch 8, Train Loss: 9.8199\n",
      "Epoch 8, Train Loss: 12.0897\n",
      "Epoch 8, Train Loss: 10.2951\n",
      "Epoch 8, Train Loss: 10.8500\n",
      "Epoch 8, Train Loss: 12.9669\n",
      "Epoch 8, Train Loss: 12.3146\n",
      "Epoch 8, Train Loss: 11.2353\n",
      "Epoch 8, Train Loss: 12.0743\n",
      "Epoch 8, Train Loss: 10.8371\n",
      "Epoch 8, Train Loss: 11.4138\n",
      "Epoch 8, Train Loss: 9.9464\n",
      "Epoch 8, Train Loss: 8.5317\n",
      "Epoch 8, Train Loss: 10.6857\n",
      "Epoch 8, Train Loss: 13.8479\n",
      "Epoch 8, Train Loss: 9.3482\n",
      "Epoch 8, Train Loss: 9.8210\n",
      "Epoch 8, Train Loss: 11.2365\n",
      "Epoch 8, Train Loss: 11.6673\n",
      "Epoch 8, Train Loss: 10.8003\n",
      "Epoch 8, Train Loss: 8.5977\n",
      "Epoch 8, Train Loss: 11.1044\n",
      "Epoch 8, Train Loss: 10.3899\n",
      "Epoch 8, Train Loss: 10.2543\n",
      "Epoch 8, Train Loss: 12.3045\n",
      "Epoch 8, Train Loss: 12.7932\n",
      "Epoch 8, Train Loss: 9.7321\n",
      "Epoch 8, Train Loss: 12.0041\n",
      "Epoch 8, Train Loss: 11.3151\n",
      "Epoch 8, Train Loss: 10.9204\n",
      "Epoch 8, Train Loss: 9.6469\n",
      "Epoch 8, Train Loss: 10.3753\n",
      "Epoch 8, Train Loss: 12.4207\n",
      "Epoch 8, Train Loss: 10.9990\n",
      "Epoch 8, Train Loss: 9.4049\n",
      "Epoch 8, Train Loss: 11.1996\n",
      "Epoch 8, Train Loss: 11.3355\n",
      "Epoch 8, Train Loss: 11.6570\n",
      "Epoch 8, Train Loss: 11.8114\n",
      "Epoch 8, Train Loss: 10.4436\n",
      "Epoch 8, Train Loss: 9.7157\n",
      "Epoch 8, Train Loss: 12.4285\n",
      "Epoch 8, Train Loss: 12.5069\n",
      "Epoch 8, Train Loss: 11.8743\n",
      "Epoch 8, Train Loss: 10.0025\n",
      "Epoch 8, Train Loss: 10.9651\n",
      "Epoch 8, Train Loss: 12.3470\n",
      "Epoch 8, Train Loss: 11.3604\n",
      "Epoch 8, Train Loss: 10.8648\n",
      "Epoch 8, Train Loss: 11.0540\n",
      "Epoch 8, Train Loss: 11.0039\n",
      "Epoch 8, Train Loss: 13.8944\n",
      "Epoch 8, Train Loss: 10.8320\n",
      "Epoch 8, Train Loss: 11.5543\n",
      "Epoch 8, Train Loss: 13.4695\n",
      "Epoch 8, Train Loss: 9.6690\n",
      "Epoch 8, Train Loss: 11.4029\n",
      "Epoch 8, Train Loss: 11.0496\n",
      "Epoch 8, Train Loss: 11.9861\n",
      "Epoch 8, Train Loss: 12.3923\n",
      "Epoch 8, Train Loss: 9.0177\n",
      "Epoch 8, Train Loss: 10.1154\n",
      "Epoch 8, Train Loss: 10.4456\n",
      "Epoch 8, Train Loss: 13.6346\n",
      "Epoch 8, Train Loss: 11.1451\n",
      "Epoch 8, Train Loss: 11.1634\n",
      "Epoch 8, Train Loss: 9.2272\n",
      "Epoch 8, Train Loss: 12.3376\n",
      "Epoch 8, Train Loss: 10.0734\n",
      "Epoch 8, Train Loss: 11.6690\n",
      "Epoch 8, Train Loss: 11.2141\n",
      "Epoch 8, Train Loss: 10.4083\n",
      "Epoch 8, Train Loss: 11.2243\n",
      "Epoch 8, Train Loss: 12.3064\n",
      "Epoch 8, Train Loss: 11.4387\n",
      "Epoch 8, Train Loss: 10.1785\n",
      "Epoch 8, Train Loss: 12.4591\n",
      "Epoch 8, Train Loss: 10.9034\n",
      "Epoch 8, Train Loss: 12.3186\n",
      "Epoch 8, Train Loss: 13.0504\n",
      "Epoch 8, Train Loss: 11.3726\n",
      "Epoch 8, Train Loss: 11.8513\n",
      "Epoch 8, Train Loss: 11.3124\n",
      "Epoch 8, Train Loss: 11.4153\n",
      "Epoch 8, Train Loss: 9.9416\n",
      "Epoch 8, Train Loss: 11.0539\n",
      "Epoch 8, Train Loss: 12.1109\n",
      "Epoch 8, Train Loss: 10.6282\n",
      "Epoch 8, Train Loss: 9.9684\n",
      "Epoch 8, Train Loss: 12.2834\n",
      "Epoch 8, Train Loss: 10.3109\n",
      "Epoch 8, Train Loss: 10.6277\n",
      "Epoch 8, Train Loss: 13.0696\n",
      "Epoch 8, Train Loss: 11.1490\n",
      "Epoch 8, Train Loss: 8.9780\n",
      "Epoch 8, Train Loss: 11.0716\n",
      "Epoch 8, Train Loss: 8.9426\n",
      "Epoch 8, Train Loss: 10.8027\n",
      "Epoch 8, Train Loss: 10.8641\n",
      "Epoch 8, Train Loss: 9.1566\n",
      "Epoch 8, Train Loss: 11.5581\n",
      "Epoch 8, Train Loss: 13.4046\n",
      "Epoch 8, Train Loss: 10.4167\n",
      "Epoch 8, Train Loss: 11.7084\n",
      "Epoch 8, Train Loss: 10.7263\n",
      "Epoch 8, Train Loss: 10.5040\n",
      "Epoch 8, Train Loss: 11.4839\n",
      "Epoch 8, Train Loss: 12.2352\n",
      "Epoch 8, Train Loss: 9.8061\n",
      "Epoch 8, Train Loss: 11.8962\n",
      "Epoch 8, Train Loss: 13.4972\n",
      "Epoch 8, Train Loss: 13.4732\n",
      "Epoch 8, Train Loss: 11.0628\n",
      "Epoch 8, Train Loss: 10.4399\n",
      "Epoch 8, Train Loss: 10.0671\n",
      "Epoch 8, Train Loss: 9.7333\n",
      "Epoch 8, Train Loss: 12.8997\n",
      "Epoch 8, Train Loss: 11.4552\n",
      "Epoch 8, Train Loss: 10.0549\n",
      "Epoch 8, Train Loss: 11.5794\n",
      "Epoch 8, Train Loss: 10.3192\n",
      "Epoch 8, Train Loss: 13.0850\n",
      "Epoch 8, Train Loss: 11.9411\n",
      "Epoch 8, Train Loss: 10.0832\n",
      "Epoch 8, Train Loss: 10.9539\n",
      "Epoch 8, Train Loss: 11.7165\n",
      "Epoch 8, Train Loss: 11.8018\n",
      "Epoch 8, Train Loss: 11.9400\n",
      "Epoch 8, Train Loss: 11.1241\n",
      "Epoch 8, Train Loss: 11.6543\n",
      "Epoch 8, Train Loss: 10.7185\n",
      "Epoch 8, Train Loss: 11.6551\n",
      "Epoch 8, Train Loss: 10.1807\n",
      "Epoch 8, Train Loss: 10.0463\n",
      "Epoch 8, Train Loss: 11.4531\n",
      "Epoch 8, Train Loss: 11.4789\n",
      "Epoch 8, Train Loss: 10.9217\n",
      "Epoch 8, Train Loss: 12.4018\n",
      "Epoch 8, Train Loss: 10.2895\n",
      "Epoch 8, Train Loss: 11.8093\n",
      "Epoch 8, Train Loss: 12.9560\n",
      "Epoch 8, Train Loss: 9.2072\n",
      "Epoch 8, Train Loss: 11.5440\n",
      "Epoch 8, Train Loss: 10.4043\n",
      "Epoch 8, Train Loss: 10.2835\n",
      "Epoch 8, Train Loss: 11.6232\n",
      "Epoch 8, Train Loss: 10.1108\n",
      "Epoch 8, Train Loss: 11.6805\n",
      "Epoch 8, Train Loss: 12.3711\n",
      "Epoch 8, Train Loss: 12.5310\n",
      "Epoch 8, Train Loss: 9.7587\n",
      "Epoch 8, Train Loss: 10.3772\n",
      "Epoch 8, Train Loss: 8.8326\n",
      "Epoch 8, Train Loss: 13.1624\n",
      "Epoch 8, Train Loss: 12.9229\n",
      "Epoch 8, Train Loss: 11.5068\n",
      "Epoch 8, Train Loss: 9.4375\n",
      "Epoch 8, Train Loss: 9.9708\n",
      "Epoch 8, Train Loss: 9.8663\n",
      "Epoch 8, Train Loss: 12.0375\n",
      "Epoch 8, Train Loss: 11.5352\n",
      "Epoch 8, Train Loss: 12.1175\n",
      "Epoch 8, Train Loss: 11.5137\n",
      "Epoch 8, Train Loss: 12.1374\n",
      "Epoch 8, Train Loss: 11.9186\n",
      "Epoch 8, Train Loss: 10.9796\n",
      "Epoch 8, Train Loss: 12.0879\n",
      "Epoch 8, Train Loss: 12.4289\n",
      "Epoch 8, Train Loss: 11.3305\n",
      "Epoch 8, Train Loss: 9.1879\n",
      "Epoch 8, Train Loss: 9.9262\n",
      "Epoch 8, Train Loss: 13.2264\n",
      "Epoch 8, Train Loss: 12.5432\n",
      "Epoch 8, Train Loss: 10.7383\n",
      "Epoch 8, Train Loss: 12.6720\n",
      "Epoch 8, Train Loss: 11.8207\n",
      "Epoch 8, Train Loss: 9.1740\n",
      "Epoch 8, Train Loss: 11.5103\n",
      "Epoch 8, Train Loss: 14.4827\n",
      "Epoch 8, Train Loss: 12.6534\n",
      "Epoch 8, Train Loss: 9.8711\n",
      "Epoch 8, Train Loss: 12.2375\n",
      "Epoch 8, Train Loss: 9.1352\n",
      "Epoch 8, Train Loss: 11.6324\n",
      "Epoch 8, Train Loss: 11.7837\n",
      "Epoch 8, Train Loss: 10.8321\n",
      "Epoch 8, Train Loss: 11.5992\n",
      "Epoch 8, Train Loss: 10.5143\n",
      "Epoch 8, Train Loss: 10.1255\n",
      "Epoch 8, Train Loss: 10.1541\n",
      "Epoch 8, Train Loss: 10.5596\n",
      "Epoch 8, Train Loss: 11.3353\n",
      "Epoch 8, Train Loss: 12.1955\n",
      "Epoch 8, Train Loss: 10.1956\n",
      "Epoch 8, Train Loss: 9.8873\n",
      "Epoch 8, Train Loss: 10.2538\n",
      "Epoch 8, Train Loss: 12.4573\n",
      "Epoch 8, Train Loss: 11.9266\n",
      "Epoch 8, Train Loss: 11.5285\n",
      "Epoch 8, Train Loss: 10.4323\n",
      "Epoch 8, Train Loss: 9.0305\n",
      "Epoch 8, Train Loss: 10.2060\n",
      "Epoch 8, Train Loss: 11.5429\n",
      "Epoch 8, Train Loss: 11.5871\n",
      "Epoch 8, Train Loss: 12.3236\n",
      "Epoch 8, Train Loss: 12.7843\n",
      "Epoch 8, Train Loss: 9.9956\n",
      "Epoch 8, Train Loss: 12.0394\n",
      "Epoch 8, Train Loss: 12.7260\n",
      "Epoch 8, Train Loss: 11.0522\n",
      "Epoch 8, Train Loss: 11.6015\n",
      "Epoch 8, Train Loss: 13.8926\n",
      "Epoch 8, Train Loss: 10.0811\n",
      "Epoch 8, Train Loss: 11.6376\n",
      "Epoch 8, Train Loss: 11.8882\n",
      "Epoch 8, Train Loss: 10.5107\n",
      "Epoch 8, Train Loss: 8.5594\n",
      "Epoch 8, Train Loss: 11.0727\n",
      "Epoch 8, Train Loss: 11.2867\n",
      "Epoch 8, Train Loss: 11.5464\n",
      "Epoch 8, Train Loss: 10.8707\n",
      "Epoch 8, Train Loss: 12.6236\n",
      "Epoch 8, Train Loss: 11.9237\n",
      "Epoch 8, Train Loss: 8.6223\n",
      "Epoch 8, Train Loss: 12.1510\n",
      "Epoch 8, Train Loss: 9.2172\n",
      "Epoch 8, Train Loss: 11.1961\n",
      "Epoch 8, Train Loss: 10.8977\n",
      "Epoch 8, Train Loss: 13.1437\n",
      "Epoch 8, Train Loss: 10.9091\n",
      "Epoch 8, Train Loss: 11.5807\n",
      "Epoch 8, Train Loss: 11.6923\n",
      "Epoch 8, Train Loss: 11.9307\n",
      "Epoch 8, Train Loss: 7.7998\n",
      "Epoch 8, Train Loss: 12.6599\n",
      "Epoch 8, Train Loss: 12.0303\n",
      "Epoch 8, Train Loss: 10.9094\n",
      "Epoch 8, Train Loss: 10.4236\n",
      "Epoch 8, Train Loss: 13.2978\n",
      "Epoch 8, Train Loss: 13.2294\n",
      "Epoch 8, Train Loss: 12.9737\n",
      "Epoch 8, Train Loss: 11.0980\n",
      "Epoch 8, Train Loss: 12.2922\n",
      "Epoch 8, Train Loss: 12.7394\n",
      "Epoch 8, Train Loss: 10.1209\n",
      "Epoch 8, Train Loss: 8.4679\n",
      "Epoch 8, Train Loss: 10.6765\n",
      "Epoch 8, Train Loss: 10.7416\n",
      "Epoch 8, Train Loss: 11.8879\n",
      "Epoch 8, Train Loss: 10.7705\n",
      "Epoch 8, Train Loss: 10.4074\n",
      "Epoch 8, Train Loss: 12.8678\n",
      "Epoch 8, Train Loss: 11.1155\n",
      "Epoch 8, Train Loss: 8.9680\n",
      "Epoch 8, Train Loss: 11.9656\n",
      "Epoch 8, Train Loss: 11.8544\n",
      "Epoch 8, Train Loss: 10.0473\n",
      "Epoch 8, Train Loss: 10.5580\n",
      "Epoch 8, Train Loss: 10.3406\n",
      "Epoch 8, Train Loss: 11.3266\n",
      "Epoch 8, Train Loss: 13.6180\n",
      "Epoch 8, Train Loss: 11.6718\n",
      "Epoch 8, Train Loss: 12.8492\n",
      "Epoch 8, Train Loss: 10.8891\n",
      "Epoch 8, Train Loss: 11.1790\n",
      "Epoch 8, Train Loss: 10.6098\n",
      "Epoch 8, Train Loss: 12.2929\n",
      "Epoch 8, Train Loss: 10.1278\n",
      "Epoch 8, Train Loss: 10.8466\n",
      "Epoch 8, Train Loss: 10.6792\n",
      "Epoch 8, Train Loss: 12.8919\n",
      "Epoch 8, Train Loss: 10.7007\n",
      "Epoch 8, Train Loss: 10.7128\n",
      "Epoch 8, Train Loss: 9.3215\n",
      "Epoch 8, Train Loss: 7.6408\n",
      "Epoch 8, Train Loss: 10.5150\n",
      "Epoch 8, Train Loss: 11.5281\n",
      "Epoch 8, Train Loss: 13.2601\n",
      "Epoch 8, Train Loss: 11.6136\n",
      "Epoch 8, Train Loss: 10.6330\n",
      "Epoch 8, Train Loss: 10.9596\n",
      "Epoch 8, Train Loss: 12.1743\n",
      "Epoch 8, Train Loss: 10.5322\n",
      "Epoch 8, Train Loss: 10.5405\n",
      "Epoch 8, Train Loss: 12.9557\n",
      "Epoch 8, Train Loss: 9.9144\n",
      "Epoch 8, Train Loss: 9.9894\n",
      "Epoch 8, Train Loss: 12.1005\n",
      "Epoch 8, Train Loss: 11.4515\n",
      "Epoch 8, Train Loss: 8.7289\n",
      "Epoch 8, Train Loss: 10.4648\n",
      "Epoch 8, Train Loss: 10.4509\n",
      "Epoch 8, Train Loss: 11.5512\n",
      "Epoch 8, Train Loss: 11.2370\n",
      "Epoch 8, Train Loss: 9.9885\n",
      "Epoch 8, Train Loss: 13.2650\n",
      "Epoch 8, Train Loss: 11.7773\n",
      "Epoch 8, Train Loss: 10.7362\n",
      "Epoch 8, Train Loss: 13.4232\n",
      "Epoch 8, Train Loss: 11.4466\n",
      "Epoch 8, Train Loss: 12.8395\n",
      "Epoch 8, Train Loss: 9.0460\n",
      "Epoch 8, Train Loss: 12.5103\n",
      "Epoch 8, Train Loss: 12.1660\n",
      "Epoch 8, Train Loss: 11.9447\n",
      "Epoch 8, Train Loss: 13.7961\n",
      "Epoch 8, Train Loss: 12.4700\n",
      "Epoch 8, Train Loss: 11.5144\n",
      "Epoch 8, Train Loss: 12.1824\n",
      "Epoch 8, Train Loss: 11.0421\n",
      "Epoch 8, Train Loss: 10.9402\n",
      "Epoch 8, Train Loss: 10.7586\n",
      "Epoch 8, Train Loss: 10.2172\n",
      "Epoch 8, Train Loss: 10.8450\n",
      "Epoch 8, Train Loss: 11.6963\n",
      "Epoch 8, Train Loss: 11.2810\n",
      "Epoch 8, Train Loss: 11.8841\n",
      "Epoch 8, Train Loss: 10.0036\n",
      "Epoch 8, Train Loss: 11.6727\n",
      "Epoch 8, Train Loss: 10.6444\n",
      "Epoch 8, Train Loss: 8.3480\n",
      "Epoch 8, Train Loss: 12.6040\n",
      "Epoch 8, Train Loss: 11.6375\n",
      "Epoch 8, Train Loss: 13.3961\n",
      "Epoch 8, Train Loss: 11.6151\n",
      "Epoch 8, Train Loss: 9.3309\n",
      "Epoch 8, Train Loss: 10.3094\n",
      "Epoch 8, Train Loss: 12.5685\n",
      "Epoch 8, Train Loss: 9.4536\n",
      "Epoch 8, Train Loss: 10.8258\n",
      "Epoch 8, Train Loss: 11.9520\n",
      "Epoch 8, Train Loss: 11.4687\n",
      "Epoch 8, Train Loss: 11.4988\n",
      "Epoch 8, Train Loss: 10.9703\n",
      "Epoch 8, Train Loss: 8.7028\n",
      "Epoch 8, Train Loss: 11.4248\n",
      "Epoch 8, Train Loss: 12.8829\n",
      "Epoch 8, Train Loss: 10.5903\n",
      "Epoch 8, Train Loss: 10.9259\n",
      "Epoch 8, Train Loss: 12.1597\n",
      "Epoch 8, Train Loss: 10.4765\n",
      "Epoch 8, Train Loss: 11.4987\n",
      "Epoch 8, Train Loss: 13.5279\n",
      "Epoch 8, Train Loss: 10.2141\n",
      "Epoch 8, Train Loss: 11.3935\n",
      "Epoch 8, Train Loss: 13.2097\n",
      "Epoch 8, Train Loss: 8.8921\n",
      "Epoch 8, Train Loss: 12.6519\n",
      "Epoch 8, Train Loss: 10.9784\n",
      "Epoch 8, Train Loss: 10.2410\n",
      "Epoch 8, Train Loss: 11.7571\n",
      "Epoch 8, Train Loss: 11.9492\n",
      "Epoch 8, Train Loss: 11.6147\n",
      "Epoch 8, Train Loss: 10.9946\n",
      "Epoch 8, Train Loss: 12.3767\n",
      "Epoch 8, Train Loss: 12.0053\n",
      "Epoch 8, Train Loss: 12.2778\n",
      "Epoch 8, Train Loss: 10.0955\n",
      "Epoch 8, Train Loss: 10.1140\n",
      "Epoch 8, Train Loss: 12.5131\n",
      "Epoch 8, Train Loss: 10.1458\n",
      "Epoch 8, Train Loss: 11.8863\n",
      "Epoch 8, Train Loss: 10.6779\n",
      "Epoch 8, Train Loss: 11.5950\n",
      "Epoch 8, Train Loss: 10.7406\n",
      "Epoch 8, Train Loss: 12.6803\n",
      "Epoch 8, Train Loss: 10.7693\n",
      "Epoch 8, Train Loss: 13.7914\n",
      "Epoch 8, Train Loss: 11.4644\n",
      "Epoch 8, Train Loss: 10.4309\n",
      "Epoch 8, Train Loss: 12.7248\n",
      "Epoch 8, Train Loss: 13.3119\n",
      "Epoch 8, Train Loss: 12.2384\n",
      "Epoch 8, Train Loss: 11.3847\n",
      "Epoch 8, Train Loss: 10.5901\n",
      "Epoch 8, Train Loss: 11.9102\n",
      "Epoch 8, Train Loss: 11.6968\n",
      "Epoch 8, Train Loss: 9.5941\n",
      "Epoch 8, Train Loss: 11.5935\n",
      "Epoch 8, Train Loss: 10.4291\n",
      "Epoch 8, Train Loss: 11.7823\n",
      "Epoch 8, Train Loss: 12.5855\n",
      "Epoch 8, Train Loss: 11.7848\n",
      "Epoch 8, Train Loss: 12.1550\n",
      "Epoch 8, Train Loss: 9.7526\n",
      "Epoch 8, Avg Loss: 11.1456, Acc: 37.49%\n",
      "Epoch 9, Avg Loss: 11.8443, Acc: 37.59%\n"
     ]
    }
   ],
   "source": [
    "# la = labelE.shape[0]\n",
    "# y = np.zeros((la, 10), dtype=np.float64)\n",
    "# y[np.arange(la), labelE] = 1.0\n",
    "\n",
    "\n",
    "#reformar las imagenes(entradas)\n",
    "imagenE = imagenes.reshape(-1, 784).astype(np.float32) / 255\n",
    "imagenP = imagens.reshape(-1, 784).astype(np.float32) / 255\n",
    "\n",
    "\n",
    "capas = load_datos()\n",
    "optimizers = DnnLib.Adam(0.001)\n",
    "entrenamiento(capas, optimizers, imagenE, yE, labelE, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3677b3b1-590a-4fa1-aa4d-a0c5ddc902b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_cero():\n",
    "\n",
    "    layer1 = DnnLib.DenseLayer(784, 128, DnnLib.ActivationType.RELU)\n",
    "    layer2 = DnnLib.DenseLayer(128, 10, DnnLib.ActivationType.SOFTMAX)\n",
    "\n",
    "    return [layer1, layer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68b7ac2-5460-4c7e-9d1d-f1e102db96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import DnnLib\n",
    "import json\n",
    "\n",
    "prueba = np.load(\"fashion_mnist_train.npz\")\n",
    "test = np.load(\"fashion_mnist_test.npz\")\n",
    "\n",
    "imagenes = prueba[\"images\"]\n",
    "labelE = prueba[\"labels\"]\n",
    "\n",
    "imagens = test[\"images\"]\n",
    "labelP = test[\"labels\"]\n",
    "\n",
    "imagenE = imagenes.reshape(-1, 784).astype(np.float32)/255\n",
    "imagenP = imagens.reshape(-1, 784).astype(np.float32)/255\n",
    "\n",
    "print(\"Train shape:\", imagenE.shape, \"Test shape:\", imagenP.shape)\n",
    "\n",
    "def to_one_hot(labels, num_classes=10):\n",
    "    h = np.zeros((labels.shape[0], num_classes), dtype=np.float32)\n",
    "    h[np.arange(labels.shape[0]), labels] = 1\n",
    "    return h\n",
    "\n",
    "yE = to_one_hot(labelE)\n",
    "yP = to_one_hot(labelP)\n",
    "\n",
    "def load_datos():\n",
    "    with open(\"mnist_entrenado.json\", \"r\") as f:\n",
    "        datos = json.load(f)\n",
    "\n",
    "    # Capa 1\n",
    "    layer1 = DnnLib.DenseLayer(784, 128, DnnLib.ActivationType.RELU)\n",
    "    layer1.set_regularizer(DnnLib.RegularizerType.L2, 0.001)\n",
    "\n",
    "    # Dropout\n",
    "    dropout1 = DnnLib.Dropout(dropout_rate=0.5)\n",
    "\n",
    "    # Capa 2\n",
    "    layer2 = DnnLib.DenseLayer(128, 10, DnnLib.ActivationType.SOFTMAX)\n",
    "    layer2.set_regularizer(DnnLib.RegularizerType.L2, 0.001)\n",
    "\n",
    "    layer1.weights = np.array(datos[\"layers\"][0][\"W\"], dtype=np.float32)  # (128,784)\n",
    "    layer1.bias = np.array(datos[\"layers\"][0][\"b\"], dtype=np.float32)  # (128,)\n",
    "\n",
    "    layer2.weights = np.array(datos[\"layers\"][1][\"W\"], dtype=np.float32)  # (10,128)\n",
    "    layer2.bias = np.array(datos[\"layers\"][1][\"b\"], dtype=np.float32)  # (10,)\n",
    "\n",
    "    return [layer1, dropout1, layer2]\n",
    "\n",
    "def forward_pass_with_dropout(layers, x, training=True):\n",
    "    activation = x\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, DnnLib.Dropout):\n",
    "            layer.training = training\n",
    "        activation = layer.forward(activation)\n",
    "    return activation\n",
    "\n",
    "def backward_pass_with_dropout(layers, grad_output):\n",
    "    grad = grad_output\n",
    "    for layer in reversed(layers):\n",
    "        grad = layer.backward(grad)\n",
    "    return grad\n",
    "\n",
    "\n",
    "def entrenamiento(capas, optimizers, x, y, label, epochs=50, batches=128):\n",
    "    n = x.shape[0]\n",
    "    for e in range(epochs):\n",
    "        r = np.random.permutation(n)\n",
    "        x_shuffled = x[r]\n",
    "        y_shuffled = y[r]\n",
    "        labels = label[r]\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        n_batches, correct, total = 0, 0, 0\n",
    "\n",
    "        for i in range(0, n, batches):\n",
    "            x_batch = x_shuffled[i:i+batches]\n",
    "            y_batch = y_shuffled[i:i+batches]\n",
    "            label_batch = labels[i:i+batches]\n",
    "\n",
    "            # Forward con dropout activo\n",
    "            output = forward_pass_with_dropout(capas, x_batch, training=True)\n",
    "\n",
    "            # perdida\n",
    "            perdida = DnnLib.cross_entropy(output, y_batch)\n",
    "\n",
    "            # Regularización\n",
    "            total_reg_loss = capas[0].compute_regularization_loss() + capas[2].compute_regularization_loss()\n",
    "            data_loss = perdida + total_reg_loss\n",
    "\n",
    "            # gradiente y backward\n",
    "            gradiente = DnnLib.softmax_crossentropy_gradient(output, y_batch)\n",
    "            gradiente = backward_pass_with_dropout(capas, gradiente)\n",
    "\n",
    "            # actualizar las capas menos el dropout\n",
    "            optimizers.update(capas[0])\n",
    "            optimizers.update(capas[2])\n",
    "\n",
    "            epoch_loss += perdida\n",
    "            n_batches += 1\n",
    "            preds = np.argmax(output, axis=1)\n",
    "            correct += np.sum(preds == label_batch)\n",
    "            total += len(label_batch)\n",
    " \n",
    "            if e % 2 == 0 and i == 0:\n",
    "                print(f\"Reg Loss: {total_reg_loss:.4f}, Total: {data_loss:.4f}\")\n",
    "\n",
    "        #AVERAGE LOSS Y ACCURACY\n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        acc = correct / total\n",
    "        if e % 5 == 0:\n",
    "            print(f\"Epoch {e}, Avg Loss: {avg_loss:.4f}, Acc: {acc*100:.2f}%\")// mi fucking kernel muere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a00d1a1-0f29-4533-8c52-6a97067e9b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n",
      "(128, 10)\n",
      "[<DnnLib.DenseLayer object at 0x7fffd3988cb0>, <DnnLib.Dropout object at 0x7fffd398a4b0>, <DnnLib.DenseLayer object at 0x7fffd3988330>]\n"
     ]
    }
   ],
   "source": [
    "cap = load_datos()\n",
    "print(cap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
