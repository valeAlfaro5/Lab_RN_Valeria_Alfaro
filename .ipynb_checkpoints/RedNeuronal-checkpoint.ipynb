{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa11ba5c-c01c-43d3-86e8-19a7b7400afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import DnnLib\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02a3552-4536-4d93-9a79-98c64ca89055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga de datos\n",
    "with open(\"mnist_mlp_pretty.json\", \"r\") as f:\n",
    "    datos = json.load(f)\n",
    "\n",
    "#carga imagenes y labels\n",
    "data = np.load(\"mnist_train.npz\")\n",
    "images = data[\"images\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "#capa1\n",
    "w1 = np.array(datos[\"layers\"][0][\"W\"])\n",
    "b1 = np.array(datos[\"layers\"][0][\"b\"])\n",
    "\n",
    "#capa2\n",
    "w2 = np.array(datos[\"layers\"][1][\"W\"])\n",
    "b2 = np.array(datos[\"layers\"][1][\"b\"])\n",
    "\n",
    "#activación por capa\n",
    "activate1 = datos[\"layers\"][0][\"activation\"]\n",
    "activate2 = datos[\"layers\"][1][\"activation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d02c5d4-95ac-4118-bb77-0e8c5ab0b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 128) (128,) (128, 10) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(w1.shape, b1.shape, w2.shape, b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b23274-7c71-418c-b5d3-d73db638e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir capas densas (ambas son densas segun el json)\n",
    "#primera capa tiene 784 entradas y 128 salidas, activacion relu\n",
    "layer1 = DnnLib.DenseLayer(784, 128, DnnLib.ActivationType.RELU)\n",
    "#segunda capa tiene 128 entradas(de capa 1) y 10 de salida, activacion softmax\n",
    "layer2 = DnnLib.DenseLayer(128, 10, DnnLib.ActivationType.SOFTMAX)\n",
    "\n",
    "#definir pesos y biases tomados del archivo\n",
    "#transponer para evitar errores\n",
    "layer1.weights = w1.T\n",
    "layer1.bias = b1.T\n",
    "\n",
    "layer2.weights = w2.T\n",
    "layer2.bias = b2.T\n",
    "\n",
    "x = np.random.rand(1, 784)\n",
    "\n",
    "output = layer1.forward(x)\n",
    "salida = layer2.forward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc25efe-5742-44d2-a4da-2f883223dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida capa 1: (1, 128)\n",
      "Salida capa 2: (1, 10)\n",
      "Predicción: 0.0\n"
     ]
    }
   ],
   "source": [
    "#predicciones de prueba\n",
    "predict = np.argmax(salida, axis =1)\n",
    "#acurracy\n",
    "acurracy = np.mean(predict == x)\n",
    "\n",
    "#verificar que funcione la salidas de cada una con su predicción\n",
    "print(\"Salida capa 1:\", output.shape)\n",
    "print(\"Salida capa 2:\", salida.shape)\n",
    "print(\"Predicción:\", acurracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73df5400-40c0-4321-becd-afed43efcf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probar con el mnist train\n",
    "#asegurar que tengan 784 entradas\n",
    "c = images.reshape(-1, 784)\n",
    "#normalizar\n",
    "c = c/255\n",
    "\n",
    "#forward de ambas capas con las imagenes\n",
    "out = layer1.forward(c)\n",
    "sal = layer2.forward(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2d9b94-9ac4-4a06-abc3-158d3f3571ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: 97.10666666666667\n"
     ]
    }
   ],
   "source": [
    "#predicción con imagenes, validar que accurate tiene los labels\n",
    "predict = np.argmax(sal, axis =1)\n",
    "#acurracy\n",
    "acurracy = np.mean(predict == labels)\n",
    "\n",
    "print(\"Predicción:\", acurracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0d9ca-57b7-4064-ba82-2363345f0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamiento de red neuronal\n",
    "#creando arreglos & variables necesarias\n",
    "\n",
    "#arreglo de layers\n",
    "layers =[layer1, layer2]\n",
    "\n",
    "#arreglo de optimizadores\n",
    "optimizers = [\n",
    "    # (\"SGD\", DnnLib.SGD(0.001)),\n",
    "    # (\"SGD+Momentum\", DnnLib.SGD(0.001, 0.9)),\n",
    "    (\"Adam\", DnnLib.Adam(0.001))\n",
    "    # (\"RMSprop\", DnnLib.RMSprop(0.001))\n",
    "]\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "y = np.zeros((60000, 10), dtype=np.float64)\n",
    "y[np.arange(60000), label] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ca637-c9cd-4303-a669-837d60cac91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion de entrenamiento\n",
    "#arreglo de layers ya definidio, arreglo de todos los optimizadores, f son las entradas del mnist-train, y es el one hot, label a lo que estoy comparando y epochs epocas predefinidas \n",
    "def entrenamiento(optimizers, f, y, label, epochs):\n",
    "    loss = []\n",
    "\n",
    "    for opt_name, optimizer in optimizers:\n",
    "        print(f\"\\n--- Training with {opt_name} ---\")\n",
    "        # Reset network weights (create new layers)\n",
    "        layers = [ layer1, layer2 ]\n",
    "        optimizer.reset()\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            #forward de ambas capas\n",
    "            output = layers[0].forward(f)\n",
    "            salida = layers[1].forward(output)\n",
    "    \n",
    "            #funcion de perdida\n",
    "            #cross entropy es mas recomendada en mnist\n",
    "            perdida = DnnLib.cross_entropy(salida, y)\n",
    "    \n",
    "            #gradiente de funcion de perdida\n",
    "            gradiente = DnnLib.cross_entropy_gradient(salida, y)\n",
    "    \n",
    "            #al tener solo dos capas se puede hacer el backpropagation directamente\n",
    "            #si no se debe utilizar for\n",
    "            #empezar por ultima capa a la primera\n",
    "            gradiente = layers[1].backward(gradiente)\n",
    "            gradiente = layers[0].backward(gradiente)\n",
    "\n",
    "            #updeater el optimizador\n",
    "            optimizer.update(layers[1])\n",
    "            optimizer.update(layers[0])\n",
    "\n",
    "            if e % 20 == 0:\n",
    "                predict = np.argmax(salida, axis =1)\n",
    "                acurracy = np.mean(predict == label)\n",
    "                loss.append(perdida)\n",
    "                print(f\"Epoch {e}, Loss: {perdida:.4f}, Accuracy: {acurracy:.4f}\")\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a1db4-b92a-4361-b09d-998bf6a1250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = []\n",
    "per = entrenamiento(optimizers, f, y, label, epochs)\n",
    "print(per)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
